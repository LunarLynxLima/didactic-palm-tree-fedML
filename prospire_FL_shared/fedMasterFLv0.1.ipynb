{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -q tensorflow_federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Parameters:\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        if dataset == 'wi_outdoor_15_buildings_8_reflections':\n",
    "            self.power_flies_dir = 'WIOutdoor15Buildings8ReflectionsRxPowerFiles/'\n",
    "            self.tx_locs_dir = 'WIOutdoor15Buildings8ReflectionsTxRxLocations/txset.txrx'\n",
    "            self.rx_locs_dir = 'WIOutdoor15Buildings8ReflectionsTxRxLocations/rxset.txrx'\n",
    "            self.buildings_file = 'WIOutdoor15Buildings8ReflectionsBuildingVertices/ConcreteBuildings.object'\n",
    "            self.foliage_file = None\n",
    "            self.xy_grid_rx = True\n",
    "            self.x_min, self.y_min, self.x_max, self.y_max = 0.0, 0.0, 500.0, 500.0\n",
    "            self.cell_width = 10.0\n",
    "            # Total number of TXs is 152 and RXs is 2340\n",
    "            self.num_sensors_list = range(10, 315, 50)\n",
    "            # self.num_train_tx_pos_list = range(10, 95, 20)\n",
    "            self.num_train_tx_pos_list = range(70, 75, 20)\n",
    "            self.num_train_tx_pos = 90\n",
    "            self.num_sensors = 200\n",
    "            self.num_exp_test_tx = 30  # Number of experimental TX positions to test\n",
    "            self.num_target_locs_for_radio_map = 200\n",
    "            self.rss_min = -109.0  # Minimum value of acceptable rss\n",
    "            self.rss_max = -2.0  # Maximum value of acceptable rss\n",
    "            self.valid_rss = self.rss_min\n",
    "            self.clip_low_rss = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Conv1D, GlobalAveragePooling1D, MaxPooling1D, \\\n",
    "    GlobalMaxPooling1D, LeakyReLU, BatchNormalization, Conv2D, MaxPool2D, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.platform import gfile\n",
    "# import tensorflow.contrib.tensorrt as trt\n",
    "# from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.keras import backend as K\n",
    "# import KerasModelToFrozenGraph as freeze\n",
    "import numpy as np\n",
    "import json, itertools, random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math, datetime\n",
    "\n",
    "\n",
    "class UnetClass:\n",
    "\n",
    "    def __init__(self, params, img_height, img_width, img_depth, var_loss=False, ):\n",
    "        self.img_height, self.img_width, self.img_depth = img_height, img_width, img_depth\n",
    "        self.para = params\n",
    "        self.min_rss = params.rss_min; self.max_rss = params.rss_max\n",
    "        self.image_preprocessing = None     # 'normalize' will cause problem with custom loss\n",
    "        if self.image_preprocessing == 'normalize':\n",
    "            self.datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "        self.normalize_rss = True   # If not using this need to check that predicted values is within range\n",
    "        self.rescale = 1.0 / (self.max_rss - self.min_rss)\n",
    "        self.var_loss = var_loss\n",
    "\n",
    "        self.use_custom_loss = True\n",
    "        self.model = self.unet_architecture()\n",
    "        self.history_file = \"unet_history.json\"; self.checkpoint_model = 'unet_best_model.h5'\n",
    "        self.model_file = 'unet_model.h5'\n",
    "        self.best_batch_size, self.best_epochs = 32, 1000    # model parameters for the nn\n",
    "        self.worker_epochs = 1000, 10\n",
    "        # self.best_batch_size, self.best_epochs = 32, 1000    # model parameters for the nn\n",
    "        self.es = EarlyStopping(monitor='val_loss', mode='min', patience=100, verbose=1)    # simple early stopping\n",
    "        self.mc = ModelCheckpoint(self.checkpoint_model, monitor='val_loss', mode='min', verbose=0,\n",
    "                                      save_best_only=True) # saves the best model\n",
    "        self.log_dir = \"logs/\" + \"fit/\" + 'Unet' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=self.log_dir, histogram_freq=1)\n",
    "\n",
    "    def unet_architecture(self):\n",
    "        alpha = 0.0  # for leaky relu\n",
    "\n",
    "        def conv_block(input, num_filters, kernel_size):\n",
    "            x = Conv2D(num_filters, kernel_size, padding=\"same\", kernel_initializer='he_normal',\n",
    "                       kernel_regularizer='l2')(input)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=alpha)(x)\n",
    "\n",
    "            x = Conv2D(num_filters, kernel_size, padding=\"same\", kernel_initializer='he_normal',\n",
    "                       kernel_regularizer='l2')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = LeakyReLU(alpha=alpha)(x)\n",
    "            return x\n",
    "\n",
    "        def encoder_block(input, num_filters, kernel_size):\n",
    "            # kernel_size = (3, 3)\n",
    "            x = conv_block(input, num_filters, kernel_size)\n",
    "            p = MaxPool2D((2, 2))(x)\n",
    "            # x = BatchNormalization()(x)\n",
    "            # p = Dropout(rate=0.25)(p)\n",
    "            return x, p\n",
    "\n",
    "        def decoder_block(input, skip_features, num_filters, kernel_size):\n",
    "            x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\", kernel_initializer='he_normal',\n",
    "                                kernel_regularizer='l2')(input)\n",
    "            # x = BatchNormalization()(x)\n",
    "            # x = LeakyReLU(alpha=alpha)(x)\n",
    "            x = Concatenate()([skip_features, x])\n",
    "            # kernel_size = (3, 3)\n",
    "            x = conv_block(x, num_filters, kernel_size)\n",
    "            return x\n",
    "\n",
    "        inputs = Input(shape=(self.img_height - 2, self.img_width - 2, self.img_depth)) # for adjustment from 50 to 48\n",
    "\n",
    "        # Encoder\n",
    "        s1, p1 = encoder_block(inputs, 32, (3, 3))\n",
    "        s2, p2 = encoder_block(p1, 64, (3, 3))\n",
    "        s3, p3 = encoder_block(p2, 128, (3, 3))\n",
    "        s4, p4 = encoder_block(p3, 256, (3, 3))\n",
    "\n",
    "        b1 = conv_block(p4, 256, (3, 3))\n",
    "\n",
    "        d1 = decoder_block(b1, s4, 256, (3, 3))\n",
    "        d2 = decoder_block(d1, s3, 128, (3, 3))\n",
    "        d3 = decoder_block(d2, s2, 64, (3, 3))\n",
    "        d4 = decoder_block(d3, s1, 32, (3, 3))\n",
    "\n",
    "        outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"relu\")(d4)\n",
    "        model = Model(inputs, outputs, name=\"U-Net\")\n",
    "        adam = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "        if self.use_custom_loss:\n",
    "            model.compile(loss=self.custom_loss, optimizer='adam')\n",
    "        else:\n",
    "            model.compile(optimizer='adam', loss=\"mean_absolute_error\")\n",
    "            # model.compile(optimizer='adam', loss=\"mean_squared_error\")\n",
    "        # model.summary()\n",
    "        return model\n",
    "\n",
    "    def custom_loss(self, y_true, y_pred):\n",
    "        img_height = y_true.shape[1]; img_width = y_true.shape[2]\n",
    "\n",
    "        if self.var_loss:\n",
    "            lambda_overestimate = 1.0\n",
    "            lambda_underestimate = 10.0\n",
    "        else:\n",
    "            lambda_overestimate = 1.0\n",
    "            lambda_underestimate = 1.0\n",
    "\n",
    "        y_true_mask = tf.where(y_true < 0.0, 0.0, 1.0)\n",
    "        y_true_mask_flattened = K.reshape(y_true_mask, (-1, img_height * img_width))\n",
    "        y_true_count_nonzero = K.sum(y_true_mask_flattened, axis=-1)\n",
    "\n",
    "        diff_loss_masked = (y_true - y_pred) * y_true_mask\n",
    "\n",
    "        underestimate_loss_mask = tf.where(diff_loss_masked > 0.0, 1.0 * lambda_underestimate, 0.0)\n",
    "        underestimate_loss_mask_flattened = K.reshape(underestimate_loss_mask, (-1, img_height * img_width))\n",
    "        underestimate_count_nonzero = K.sum(underestimate_loss_mask_flattened, axis=-1)\n",
    "\n",
    "        overestimate_loss_mask = tf.where(diff_loss_masked < 0.0, 1.0 * lambda_overestimate, 0.0)\n",
    "        overestimate_loss_mask_flattened = K.reshape(overestimate_loss_mask, (-1, img_height * img_width))\n",
    "        overestimate_count_nonzero = K.sum(overestimate_loss_mask_flattened, axis=-1)\n",
    "\n",
    "        diff_loss_masked = tf.where(diff_loss_masked > 0.0, diff_loss_masked * lambda_underestimate, diff_loss_masked)\n",
    "        diff_loss_masked = tf.where(diff_loss_masked < 0.0, diff_loss_masked * lambda_overestimate, diff_loss_masked)\n",
    "        abs_loss_masked = tf.abs(diff_loss_masked)\n",
    "        loss_masked = abs_loss_masked\n",
    "\n",
    "        loss_masked = K.reshape(loss_masked, (-1, img_height * img_width))\n",
    "        sum_loss_masked = K.sum(loss_masked, axis=-1)\n",
    "        mean_loss_masked = sum_loss_masked / (underestimate_count_nonzero + overestimate_count_nonzero)\n",
    "        # mean_loss_masked = sum_loss_masked / y_true_count_nonzero\n",
    "\n",
    "        return mean_loss_masked\n",
    "\n",
    "    def training(self, train_x, train_y, start_training, worker_epochs = -1):\n",
    "        if not start_training:\n",
    "            self.model = load_model(self.model_file, custom_objects={'custom_loss': self.custom_loss})\n",
    "            return\n",
    "\n",
    "        if self.normalize_rss:\n",
    "            if self.use_custom_loss:\n",
    "                train_y = np.where(train_y == 0.0, self.min_rss - 10.0, train_y)\n",
    "            else:\n",
    "                train_y = np.where(train_y == 0.0, self.min_rss, train_y)\n",
    "            train_y = train_y - self.min_rss\n",
    "            train_y = train_y * self.rescale\n",
    "        # print(train_x.shape, train_y.shape)\n",
    "        train_x = np.transpose(train_x, [0, 2, 3, 1])   # for channel last orientation\n",
    "        train_y = train_y.reshape(tuple(list(train_y.shape) + [1]))\n",
    "        # print(train_x.shape, train_y.shape)\n",
    "        # remove the outermost rows and columns for easier integration with UNET structure\n",
    "        train_x = train_x[:, 1:-1, 1:-1, :]; train_y = train_y[:, 1:-1, 1:-1, :]\n",
    "        print('Train and test shape for UNET', train_x.shape, train_y.shape)\n",
    "        print('Train and test set data size', train_x.nbytes, train_y.nbytes)\n",
    "\n",
    "        if worker_epochs != -1:\n",
    "            self.best_epochs = worker_epochs\n",
    "\n",
    "        if self.image_preprocessing == 'normalize':\n",
    "            train_idxs = np.random.choice(np.arange(train_x.shape[0]), size=int(train_x.shape[0] * 0.8), replace=False)\n",
    "            val_idxs = list(set(np.arange(train_x.shape[0])) - set(train_idxs))\n",
    "\n",
    "            x_val, y_val = train_x[val_idxs, ...], train_y[val_idxs, ...]\n",
    "            train_x, train_y = train_x[train_idxs, ...], train_y[train_idxs, ...]\n",
    "            print('Train_x and train_y shape for UNET', train_x.shape, train_y.shape)\n",
    "            print('val_x and val_y shape for UNET', x_val.shape, y_val.shape)\n",
    "\n",
    "            self.datagen.fit(train_x)\n",
    "\n",
    "            history = self.model.fit(self.datagen.flow(train_x, train_y, batch_size=self.best_batch_size),\n",
    "                                     steps_per_epoch=math.ceil(len(train_x) / float(self.best_batch_size)),\n",
    "                                     epochs=self.best_epochs,\n",
    "                                     callbacks=[self.es, self.mc],\n",
    "                                     validation_data=self.datagen.flow(x_val, y_val, batch_size=self.best_batch_size),\n",
    "                                     validation_steps=math.ceil(len(x_val) / float(self.best_batch_size)),\n",
    "                                     verbose=0)\n",
    "\n",
    "        else:\n",
    "            history = self.model.fit(train_x, train_y,\n",
    "                                     validation_split=0.2,\n",
    "                                     batch_size=self.best_batch_size,\n",
    "                                     epochs=self.best_epochs,\n",
    "                                     callbacks=[self.es, self.mc, self.tensorboard_callback],\n",
    "                                     verbose=1,\n",
    "                                     shuffle=True)\n",
    "\n",
    "        if self.use_custom_loss:\n",
    "            self.model = load_model(self.checkpoint_model, custom_objects={'custom_loss': self.custom_loss})\n",
    "        else:\n",
    "            self.model.load_weights(self.checkpoint_model)  # load the saved best model\n",
    "        self.model.save(self.model_file)        # Save the model for future use\n",
    "        with open(self.history_file, \"w\") as json_file:     # save the history in a file\n",
    "            json.dump(history.history, json_file)\n",
    "        print('best_val_loss, best_train_loss', self.get_train_stats())\n",
    "\n",
    "    # Returns the validation loss and train loss for the chosen model\n",
    "    def get_train_stats(self):\n",
    "        with open(self.history_file, \"r\") as json_file:\n",
    "            history = json.load(json_file)\n",
    "        best_val_loss = min(history['val_loss'])\n",
    "        i, = np.where(np.array(history['val_loss']) == best_val_loss)\n",
    "        best_idx = i[0]\n",
    "        best_train_loss = history['loss'][best_idx]\n",
    "        return best_val_loss, best_train_loss\n",
    "\n",
    "    def predict_rss(self, test_x, batch=False):\n",
    "        if len(test_x.shape) == 3:\n",
    "            test_x = test_x.reshape(tuple([1] + list(test_x.shape)))\n",
    "        test_x = np.transpose(test_x, [0, 2, 3, 1])     # for making channels last\n",
    "        test_x = test_x[:, 1:-1, 1:-1, :]       # for making images 48x48\n",
    "\n",
    "        if self.image_preprocessing == 'normalize':\n",
    "            test_iterator = self.datagen.flow(test_x, None, batch_size=1)\n",
    "            test_x = test_iterator.next()\n",
    "\n",
    "        tx = timeit.default_timer()\n",
    "        if batch:\n",
    "            predicted_values = self.model.predict(test_x, batch_size=1024, verbose=0)\n",
    "        else:\n",
    "            # predicted_values = self.model.predict(test_x, verbose=0)\n",
    "            predicted_values = self.model(test_x, training=False)\n",
    "        # print(timeit.default_timer() - tx)\n",
    "\n",
    "        if self.normalize_rss:\n",
    "            rss_values = predicted_values / self.rescale\n",
    "            rss_values = rss_values + self.min_rss\n",
    "        else:\n",
    "            rss_values = predicted_values\n",
    "        rss_values = np.where(test_x[..., 1] == 0.0, 0.0, rss_values[..., 0])  # use predictions only for active RX locs\n",
    "        # make the images back to 50x50\n",
    "        temp_res = np.zeros((rss_values.shape[0], self.img_height, self.img_width))\n",
    "        temp_res[:, 1:-1, 1:-1] = rss_values\n",
    "        rss_values = temp_res\n",
    "        if not batch:\n",
    "            return rss_values[0, ...]\n",
    "        else:\n",
    "            return rss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sub-data : 2;  train_x_images[0].shape :  (2, 4, 50, 50) ; train_y_images[0].shape :  (2, 50, 50) ; test_x_images.shape :  (30, 4, 50, 50) ; test_y_images.shape :  (30, 50, 50)\n",
      "Train and test shape for UNET (2, 48, 48, 4) (2, 48, 48, 1)\n",
      "Train and test set data size 147456 36864\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 63.1688 - val_loss: 61.7287\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 61.8087 - val_loss: 60.0345\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 60.0308 - val_loss: 58.2344\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 58.2490 - val_loss: 56.3913\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 56.3755 - val_loss: 54.5375\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 54.5278"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 105\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest error\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39msum(temp_err) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mcount_nonzero(temp_err))\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m## main code base ends here\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[58], line 84\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Train local models\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m worker \u001b[38;5;129;01min\u001b[39;00m workers:\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_local_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Federated averaging\u001b[39;00m\n\u001b[1;32m     87\u001b[0m federated_averaging(global_nunet_obj_rti\u001b[38;5;241m.\u001b[39mmodel, [worker_obj\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mfor\u001b[39;00m worker_obj \u001b[38;5;129;01min\u001b[39;00m workers],  [\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mn_workers]\u001b[38;5;241m*\u001b[39mn_workers)\n",
      "Cell \u001b[0;32mIn[58], line 52\u001b[0m, in \u001b[0;36mFederatedWorker.train_local_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_local_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Train local model and return training time, val_loss, and train_loss\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnunet_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_x_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_y_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     54\u001b[0m     val_loss, train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_train_stats()\n",
      "Cell \u001b[0;32mIn[53], line 193\u001b[0m, in \u001b[0;36mUnetClass.training\u001b[0;34m(self, train_x, train_y, start_training, worker_epochs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatagen\u001b[38;5;241m.\u001b[39mflow(train_x, train_y, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_batch_size),\n\u001b[1;32m    185\u001b[0m                              steps_per_epoch\u001b[38;5;241m=\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(train_x) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_batch_size)),\n\u001b[1;32m    186\u001b[0m                              epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_epochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m                              validation_steps\u001b[38;5;241m=\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(x_val) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_batch_size)),\n\u001b[1;32m    190\u001b[0m                              verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_custom_loss:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_model, custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_loss})\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/engine/training.py:1850\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1847\u001b[0m     }\n\u001b[1;32m   1848\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1850\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1851\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/callbacks.py:453\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    451\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 453\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/callbacks.py:2844\u001b[0m, in \u001b[0;36mTensorBoard.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_epoch_metrics(epoch, logs)\n\u001b[1;32m   2843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistogram_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2844\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_freq \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2847\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_embeddings(epoch)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/src/callbacks.py:2924\u001b[0m, in \u001b[0;36mTensorBoard._log_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m   2922\u001b[0m \u001b[38;5;66;03m# Add a suffix to prevent summary tag name collision.\u001b[39;00m\n\u001b[1;32m   2923\u001b[0m histogram_weight_name \u001b[38;5;241m=\u001b[39m weight_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/histogram\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2924\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistogram_weight_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\n\u001b[1;32m   2926\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_images:\n\u001b[1;32m   2928\u001b[0m     \u001b[38;5;66;03m# Add a suffix to prevent summary tag name\u001b[39;00m\n\u001b[1;32m   2929\u001b[0m     \u001b[38;5;66;03m# collision.\u001b[39;00m\n\u001b[1;32m   2930\u001b[0m     image_weight_name \u001b[38;5;241m=\u001b[39m weight_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/image\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:196\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(name, data, step, buckets, description)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@lazy_tensor_creator\u001b[39m\u001b[38;5;241m.\u001b[39mLazyTensorCreator\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_tensor\u001b[39m():\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _buckets(data, buckets)\n\u001b[0;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/summary_ops_v2.py:813\u001b[0m, in \u001b[0;36mwrite\u001b[0;34m(tag, tensor, step, metadata, name)\u001b[0m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([write_summary_op]):\n\u001b[1;32m    811\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m constant_op\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 813\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43msmart_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshould_record_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nothing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummary_cond\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    816\u001b[0m   ops\u001b[38;5;241m.\u001b[39madd_to_collection(ops\u001b[38;5;241m.\u001b[39mGraphKeys\u001b[38;5;241m.\u001b[39m_SUMMARY_COLLECTION, op)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/smart_cond.py:53\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m pred_value:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrue_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m false_fn()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/summary_ops_v2.py:793\u001b[0m, in \u001b[0;36mwrite.<locals>.record\u001b[0;34m()\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;66;03m# Note the identity to move the tensor to the CPU.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu:0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 793\u001b[0m   summary_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(tensor) \u001b[38;5;28;01melse\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(\n\u001b[1;32m    794\u001b[0m       tensor)\n\u001b[1;32m    795\u001b[0m   \u001b[38;5;66;03m# For DTensor, the device scope above doesn't work, we need to\u001b[39;00m\n\u001b[1;32m    796\u001b[0m   \u001b[38;5;66;03m# explicitly copy the resource tensor to host mesh, which is a cpu\u001b[39;00m\n\u001b[1;32m    797\u001b[0m   \u001b[38;5;66;03m# mesh.\u001b[39;00m\n\u001b[1;32m    798\u001b[0m   writer \u001b[38;5;241m=\u001b[39m _summary_state\u001b[38;5;241m.\u001b[39mwriter\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorboard/util/lazy_tensor_creator.py:66\u001b[0m, in \u001b[0;36mLazyTensorCreator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m _CALL_IN_PROGRESS_SENTINEL\n\u001b[0;32m---> 66\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:194\u001b[0m, in \u001b[0;36mhistogram.<locals>.lazy_tensor\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@lazy_tensor_creator\u001b[39m\u001b[38;5;241m.\u001b[39mLazyTensorCreator\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlazy_tensor\u001b[39m():\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_buckets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuckets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:293\u001b[0m, in \u001b[0;36m_buckets\u001b[0;34m(data, bucket_count)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtranspose(a\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstack([edges, edges, bucket_counts]))\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcond(\n\u001b[1;32m    290\u001b[0m         has_single_value, when_single_value, when_multiple_values\n\u001b[1;32m    291\u001b[0m     )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_empty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_empty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_nonempty\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/cond.py:343\u001b[0m, in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    244\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcond_for_tf_v2\u001b[39m(pred, true_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, false_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Return `true_fn()` if the predicate `pred` is true else `false_fn()`.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m  Note: This op is automatically used in a `tf.function` to convert Python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:588\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       _log_deprecation(\n\u001b[1;32m    582\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    583\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    587\u001b[0m           instructions)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/cond.py:142\u001b[0m, in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse_fn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 142\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_cond_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mEnableControlFlowV2(ops\u001b[38;5;241m.\u001b[39mget_default_graph()):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/cond.py:387\u001b[0m, in \u001b[0;36m_eager_cond_implementation\u001b[0;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[1;32m    385\u001b[0m   result \u001b[38;5;241m=\u001b[39m true_fn()\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mfalse_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m    389\u001b[0m   result \u001b[38;5;241m=\u001b[39m _UnpackIfSingleton(result)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:289\u001b[0m, in \u001b[0;36m_buckets.<locals>.when_nonempty\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m     bucket_counts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\n\u001b[1;32m    284\u001b[0m         tf\u001b[38;5;241m.\u001b[39mconcat([zeroes[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], [data_size]], \u001b[38;5;241m0\u001b[39m)[:bucket_count],\n\u001b[1;32m    285\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtranspose(a\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstack([edges, edges, bucket_counts]))\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_single_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_single_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen_multiple_values\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/cond.py:343\u001b[0m, in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcond\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    244\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcond_for_tf_v2\u001b[39m(pred, true_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, false_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Return `true_fn()` if the predicate `pred` is true else `false_fn()`.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m  Note: This op is automatically used in a `tf.function` to convert Python\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:588\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       _log_deprecation(\n\u001b[1;32m    582\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    583\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    587\u001b[0m           instructions)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/cond.py:142\u001b[0m, in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfalse_fn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 142\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eager_cond_implementation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfalse_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Always enable control flow v2 if building a function, regardless of toggle.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39mEnableControlFlowV2(ops\u001b[38;5;241m.\u001b[39mget_default_graph()):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/cond.py:387\u001b[0m, in \u001b[0;36m_eager_cond_implementation\u001b[0;34m(pred, true_fn, false_fn, strict, name)\u001b[0m\n\u001b[1;32m    385\u001b[0m   result \u001b[38;5;241m=\u001b[39m true_fn()\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 387\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mfalse_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m    389\u001b[0m   result \u001b[38;5;241m=\u001b[39m _UnpackIfSingleton(result)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorboard/plugins/histogram/summary_v2.py:265\u001b[0m, in \u001b[0;36m_buckets.<locals>.when_nonempty.<locals>.when_multiple_values\u001b[0;34m()\u001b[0m\n\u001b[1;32m    258\u001b[0m one_hots \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(\n\u001b[1;32m    259\u001b[0m     clamped_indices, depth\u001b[38;5;241m=\u001b[39mbucket_count, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[1;32m    260\u001b[0m )\n\u001b[1;32m    261\u001b[0m bucket_counts \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\n\u001b[1;32m    262\u001b[0m     tf\u001b[38;5;241m.\u001b[39mreduce_sum(input_tensor\u001b[38;5;241m=\u001b[39mone_hots, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    263\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[1;32m    264\u001b[0m )\n\u001b[0;32m--> 265\u001b[0m edges \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# Ensure edges[-1] == max_, which TF's linspace implementation does not\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# do, leaving it subject to the whim of floating point rounding error.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m edges \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([edges[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], [max_]], \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:185\u001b[0m, in \u001b[0;36mlinspace_nd\u001b[0;34m(start, stop, num, name, axis)\u001b[0m\n\u001b[1;32m    182\u001b[0m expanded_stop \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mexpand_dims(stop, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    184\u001b[0m shape \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(expanded_start)\n\u001b[0;32m--> 185\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    187\u001b[0m axis \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mwhere_v2(axis \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, axis, ndims \u001b[38;5;241m+\u001b[39m axis)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# The purpose is to avoid having negative values when repeating.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1165\u001b[0m, in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1163\u001b[0m   var_empty \u001b[38;5;241m=\u001b[39m constant([], dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m   1164\u001b[0m   packed_begin \u001b[38;5;241m=\u001b[39m packed_end \u001b[38;5;241m=\u001b[39m packed_strides \u001b[38;5;241m=\u001b[39m var_empty\n\u001b[0;32m-> 1165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_begin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_strides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1338\u001b[0m, in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1336\u001b[0m   strides \u001b[38;5;241m=\u001b[39m ones_like(begin)\n\u001b[0;32m-> 1338\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m parent_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:10930\u001b[0m, in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m  10929\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m> 10930\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10931\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStridedSlice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbegin_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10932\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mellipsis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10933\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshrink_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10934\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m  10935\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import timeit, time\n",
    "from UnetClass import UnetClass\n",
    "from Parameters import Parameters\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "dataset = 'wi_outdoor_15_buildings_8_reflections'  # dataset to use. For other available datasets, see Parameters.py\n",
    "para = Parameters(dataset)\n",
    "num_pixels_x = int((para.x_max - para.x_min) / para.cell_width)  # image width\n",
    "num_pixels_y = int((para.y_max - para.y_min) / para.cell_width)  # image height\n",
    "# for sampling RXs and creating images\n",
    "num_samples = 40\n",
    "num_images = 200\n",
    "\n",
    "gen_plots = False\n",
    "use_aug = False\n",
    "\n",
    "start_training = True\n",
    "n_workers = 2 # number of workers to use for federated learning :: 1 means traditional learning without FL\n",
    "\n",
    "def augmentation(train_x_images, train_y_images):\n",
    "    train_x_images_aug = []; train_y_images_aug = []\n",
    "    for i in range(train_x_images.shape[0]):\n",
    "        tx_img = train_x_images[i, 0, ...]\n",
    "        rx_img = train_x_images[i, 1, ...]\n",
    "        map_img = train_x_images[i, 2, ...]\n",
    "        rti_img = train_x_images[i, 3, ...]\n",
    "        rss_img = train_y_images[i]\n",
    "\n",
    "        non_zero_pixels = np.nonzero(rx_img)\n",
    "        non_zero_pixels = np.array(list(zip(non_zero_pixels[0], non_zero_pixels[1])))\n",
    "\n",
    "        for j in range(num_images):\n",
    "            selected_pixels = np.random.choice(non_zero_pixels.shape[0], size=num_samples, replace=False)\n",
    "            selected_pixels = non_zero_pixels[selected_pixels, :]\n",
    "            selected_pixels = tuple(list(zip(*selected_pixels)))\n",
    "\n",
    "            rx_img_new = np.zeros_like(rx_img)\n",
    "            rx_img_new[selected_pixels] = rx_img[selected_pixels]\n",
    "            rti_img_new = np.zeros_like(rti_img)\n",
    "            rti_img_new[selected_pixels] = rti_img[selected_pixels]\n",
    "            new_data = np.stack([tx_img, rx_img_new, map_img, rti_img_new], axis=0)\n",
    "            train_x_images_aug.append(new_data)\n",
    "\n",
    "            rss_img_new = np.zeros_like(rss_img)\n",
    "            rss_img_new[selected_pixels] = rss_img[selected_pixels]\n",
    "            train_y_images_aug.append(rss_img_new)\n",
    "\n",
    "            # plotting some sample images\n",
    "            if gen_plots:\n",
    "                fig, axs = plt.subplots(nrows=2, ncols=5, constrained_layout=True)\n",
    "                plot_data = [tx_img, rx_img, map_img, rti_img, rss_img, new_data[0, ...], new_data[1, ...],\n",
    "                             new_data[2, ...], new_data[3, ...], rss_img_new]\n",
    "                titles = ['TX', 'RX', 'Map', 'RTI', 'RSS', 'TX', 'RX_samp', 'Map', 'RTI_samp', 'RSS_samp']\n",
    "                for idx, ax in enumerate(axs.flat):\n",
    "                    ax.grid(True)\n",
    "                    vec = plot_data[idx]; title = titles[idx]\n",
    "\n",
    "                    im = ax.imshow(vec, aspect='auto', cmap='viridis', interpolation=\"nearest\")\n",
    "                    cbar = fig.colorbar(im, ax=ax, orientation=\"vertical\", shrink=0.99, aspect=40, pad=0.01)\n",
    "                    cbar.ax.tick_params()\n",
    "\n",
    "                    ax.set_xticks(np.arange(0, 50, 5) - 0.5); ax.set_xticklabels(10 * np.arange(0, 50, 5), rotation=45)\n",
    "                    ax.set_yticks(np.arange(0, 50, 5) + 0.5); ax.set_yticklabels(10 * np.flip(np.arange(0, 50, 5)))\n",
    "                    # ax.tick_params(labelsize=labelsize)\n",
    "                    ax.set_title(title)\n",
    "                plt.show()\n",
    "    return [np.array(train_x_images_aug), np.array(train_y_images_aug)]\n",
    "\n",
    "def federated_averaging(global_model, worker_models, weights):\n",
    "    global_weights = global_model.get_weights()\n",
    "    num_workers = len(worker_models)\n",
    "    \n",
    "    # Initialize averaged weights\n",
    "    new_weights = [np.zeros_like(w) for w in global_weights]\n",
    "    \n",
    "    # Weighted average of local models' weights\n",
    "    for i, worker_model in enumerate(worker_models):\n",
    "        local_weights = worker_model.get_weights()\n",
    "        for j in range(len(new_weights)):\n",
    "            new_weights[j] += local_weights[j] * weights[i]\n",
    "    \n",
    "    # Set the averaged weights to the global model\n",
    "    global_model.set_weights(new_weights)\n",
    "    # return global_model\n",
    "\n",
    "class FederatedWorker:\n",
    "    def __init__(self, worker_id, nunet_obj, train_x_images, train_y_images, params, worker_epochs=100):\n",
    "        self.worker_id = worker_id\n",
    "        self.nunet_obj = nunet_obj\n",
    "        self.model = nunet_obj.model\n",
    "        self.train_x_images = train_x_images\n",
    "        self.train_y_images = train_y_images\n",
    "        self.worker_epochs = worker_epochs\n",
    "        self.params = params\n",
    "\n",
    "    def train_local_model(self):\n",
    "        # Train local model and return training time, val_loss, and train_loss\n",
    "        start_time = time.time()\n",
    "        self.nunet_obj.training(self.train_x_images, self.train_y_images, start_training=True, worker_epochs=self.worker_epochs)\n",
    "        training_time = time.time() - start_time\n",
    "        val_loss, train_loss = self.model.get_train_stats()\n",
    "        return val_loss, train_loss, training_time\n",
    "    \n",
    "\n",
    "def main():\n",
    "    r_train_x_images, r_train_y_images = np.load('train_x_images_rti.npy', 'r'), np.load('train_y_images_rti.npy', 'r')\n",
    "    test_x_images, test_y_images = np.load('test_x_images_rti.npy', 'r'), np.load('test_y_images_rti.npy', 'r')\n",
    "    train_x_images, train_y_images = np.array_split(r_train_x_images, n_workers), np.array_split(r_train_y_images, n_workers)\n",
    "    \n",
    "    print(f'number of sub-data : {len(train_y_images)}; ', \n",
    "          'train_x_images[0].shape : ', train_x_images[0].shape, '; train_y_images[0].shape : ', train_y_images[0].shape, \n",
    "          '; test_x_images.shape : ', test_x_images.shape, '; test_y_images.shape : ', test_y_images.shape)    \n",
    "\n",
    "    if use_aug:\n",
    "        train_x_images, train_y_images = augmentation(train_x_images, train_y_images)\n",
    "        test_x_images, test_y_images = augmentation(test_x_images, test_y_images)\n",
    "        print('Post augmentation:')\n",
    "        print('train_x_images.shape, train_y_images.shape, test_x_images.shape, test_y_images.shape',\n",
    "              train_x_images.shape, train_y_images.shape, test_x_images.shape, test_y_images.shape)\n",
    "\n",
    "    global_nunet_obj_rti = UnetClass(para, num_pixels_x, num_pixels_y, train_x_images[-1].shape[1], False)\n",
    "    workers_nunet_obj_rti = [UnetClass(para, num_pixels_x, num_pixels_y, train_x_images[-1].shape[1], False) for i in range(n_workers)]\n",
    "\n",
    "    # intialize workers\n",
    "    workers = [FederatedWorker(i, workers_nunet_obj_rti[i], train_x_images[i], train_y_images[i], para) for i in range(n_workers)]\n",
    "    epochs = UnetClass.best_epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        \n",
    "        # Train local models\n",
    "        for worker in workers:\n",
    "            worker.train_local_model()\n",
    "        \n",
    "        # Federated averaging\n",
    "        federated_averaging(global_nunet_obj_rti.model, [worker_obj.model for worker_obj in workers],  [1/n_workers]*n_workers)\n",
    "\n",
    "    # compute train error\n",
    "    temp_pred = global_nunet_obj_rti.predict_rss(r_train_x_images, True)\n",
    "    temp_err = np.where(train_y_images == 0.0, r_train_y_images, np.abs(temp_pred - train_y_images))\n",
    "    train_error = (np.sum(temp_err)) / np.count_nonzero(temp_err)\n",
    "    print('train_error', train_error)\n",
    "    # prediction\n",
    "    nunet_rti_prediction = []\n",
    "    for item, vals in zip(test_x_images, test_y_images):\n",
    "        temp_unet = global_nunet_obj_rti.predict_rss(item)\n",
    "        nunet_rti_prediction.append(temp_unet)\n",
    "    nunet_rti_prediction = np.reshape(np.array(nunet_rti_prediction), test_y_images.shape)\n",
    "    temp_err = np.where(test_y_images == 0.0, test_y_images, np.abs(nunet_rti_prediction - test_y_images))\n",
    "    print('test error', np.sum(temp_err) / np.count_nonzero(temp_err))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "## main code base ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
