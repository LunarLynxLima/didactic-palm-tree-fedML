{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["eoLdAHqaS_9z","iKP0n0p2S5w4","1yxVpUfz0evs","DnR6E7GeRRt1","jbk5x7mH0evt","-XV85VLTxr67","Ukj03pGgifka","atbGXh69y-Sm","kHok7c7o0evu","GUMm_YR10evv"],"gpuType":"T4","provenance":[{"file_id":"https://github.com/LunarLynxLima/ubiquitous-chainsaw--fedML/blob/main/Copy_of_WiFedML.ipynb","timestamp":1718831158388}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Env building and Importing libiraries","metadata":{"id":"eoLdAHqaS_9z"}},{"cell_type":"code","source":"# ! pip install -q tensorflow numpy matplotlib seaborn scikit-learn\n! pip install -q tensorflow-model-optimization","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26736,"status":"ok","timestamp":1719922164789,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"},"user_tz":-330},"id":"1cBVyi1P0evp","outputId":"46442686-eb5c-4351-bbb9-26004b41d440","execution":{"iopub.status.busy":"2024-07-02T21:01:03.069565Z","iopub.execute_input":"2024-07-02T21:01:03.069948Z","iopub.status.idle":"2024-07-02T21:01:15.231478Z","shell.execute_reply.started":"2024-07-02T21:01:03.069916Z","shell.execute_reply":"2024-07-02T21:01:15.230382Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*\n# !zip -r file.zip /kaggle/working\n# !rm /kaggle/working/file.zip","metadata":{"execution":{"iopub.status.busy":"2024-07-02T21:07:26.810174Z","iopub.execute_input":"2024-07-02T21:07:26.810820Z","iopub.status.idle":"2024-07-02T21:07:27.805246Z","shell.execute_reply.started":"2024-07-02T21:07:26.810782Z","shell.execute_reply":"2024-07-02T21:07:27.804055Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n# from tensorflow.keras.datasets import mnist\n# from sklearn.metrics import classification_report, confusion_matrix\n# from sklearn.model_selection import train_test_split\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow import keras\n# from tensorflow.keras import layers\n# import tensorflow_model_optimization as tfmot\n# from tensorflow_model_optimization.python.core.keras.compat import keras\n\nimport time\nimport numpy as np# Import the 'models' module from Keras\nimport pandas as pd\nimport tensorflow as tf\n# from tensorflow.keras import models\n# from tensorflow.keras import layers\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow_model_optimization.python.core.keras.compat import keras\n\nVERBOSE = 2\nEPOCHS = 5","metadata":{"id":"GP1dZv0p0evr","executionInfo":{"status":"ok","timestamp":1719922174476,"user_tz":-330,"elapsed":9691,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"execution":{"iopub.status.busy":"2024-07-02T21:01:15.240103Z","iopub.execute_input":"2024-07-02T21:01:15.240431Z","iopub.status.idle":"2024-07-02T21:01:15.251354Z","shell.execute_reply.started":"2024-07-02T21:01:15.240406Z","shell.execute_reply":"2024-07-02T21:01:15.250454Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Helper functions","metadata":{"id":"iKP0n0p2S5w4"}},{"cell_type":"code","source":"def compile_model(model, optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']):\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    return model\n\ndef create_model(precision: str = 'float32'):\n    if precision == 'float32':\n        precision = tf.float32\n        model = keras.Sequential([\n            keras.layers.InputLayer(input_shape=(28, 28, 1)),\n            keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n            keras.layers.MaxPooling2D(pool_size=(2, 2)),\n            keras.layers.Flatten(),\n            keras.layers.Dense(64, activation='relu'),\n            keras.layers.Dense(10, activation='softmax')\n        ])\n    elif precision == 'float16':\n        precision = tf.float16\n        model = keras.Sequential([\n            keras.layers.InputLayer(input_shape=(28, 28)),\n            keras.layers.Reshape(target_shape=(28, 28, 1)),\n            keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu', dtype=precision),\n            keras.layers.MaxPooling2D(pool_size=(2, 2)),\n            keras.layers.Flatten(),\n            keras.layers.Dense(64, dtype=precision),\n            keras.layers.Dense(10, dtype=precision)\n        ])\n    else:\n        raise ValueError(\"Unsupported precision type (use 'float32', 'float16').\")\n\n    return compile_model(model)","metadata":{"id":"ryuqtoLa8OKX","executionInfo":{"status":"ok","timestamp":1719922174477,"user_tz":-330,"elapsed":41,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"execution":{"iopub.status.busy":"2024-07-02T21:52:35.384126Z","iopub.execute_input":"2024-07-02T21:52:35.384554Z","iopub.status.idle":"2024-07-02T21:52:35.394982Z","shell.execute_reply.started":"2024-07-02T21:52:35.384522Z","shell.execute_reply":"2024-07-02T21:52:35.394139Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def save_tflite_model(tflite_model, model_path = None, VERBOSE:int = 0):\n    \"\"\"\n    model_path : Given tflite model(string.tflite), this function will save the tflite model on the model path\n    \"\"\"\n    if model_path is not None:\n        with open(model_path, 'wb') as f:\n            f.write(tflite_model)\n            if VERBOSE : print(f\"Model saved as {model_path}\")\n    else:\n        raise ValueError(\"Model path must be provided.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-02T21:52:40.989514Z","iopub.execute_input":"2024-07-02T21:52:40.989853Z","iopub.status.idle":"2024-07-02T21:52:40.996185Z","shell.execute_reply.started":"2024-07-02T21:52:40.989827Z","shell.execute_reply":"2024-07-02T21:52:40.995069Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def custom_evaluate(interpreter, x_test, y_test, quantization_type:str = 'DEFAULT'):\n    if quantization_type == 'int8':\n        x_test = x_test.astype(np.int8)\n    elif quantization_type == 'uint8':\n        x_test = x_test.astype(np.uint8)\n    elif quantization_type == 'int16':\n        x_test = x_test.astype(np.int16)\n    elif quantization_type == 'float16':\n        x_test = x_test.astype(np.float16)\n    elif quantization_type == 'DEFAULT' or quantization_type == 'float32':\n        x_test = x_test.astype(np.float32)\n    else:\n        raise ValueError(\"Unsupported quantization type.\")\n\n    input_index = interpreter.get_input_details()[0][\"index\"]\n    output_index = interpreter.get_output_details()[0][\"index\"]\n\n    # Run predictions on every image in the \"test\" dataset.\n    y_pred = []\n    for i, test_image in enumerate(x_test):\n        # Pre-processing: add batch dimension and convert to float32\n        # to match with the model's input data format.\n        test_image = np.expand_dims(test_image, axis=0)\n        # test_image = test_image.astype(np.float32)\n        interpreter.set_tensor(input_index, test_image)\n\n        # Run inference.\n        interpreter.invoke()\n\n        # Post-processing: remove batch dimension and find the digit with highest probability.\n        output = interpreter.tensor(output_index)\n        digit = np.argmax(output()[0])\n        y_pred.append(digit)\n\n    # Compare prediction results with ground truth labels to calculate accuracy.\n    y_pred = np.array(y_pred)\n    accuracy = (y_pred == y_test).mean()\n    return accuracy , y_pred","metadata":{"execution":{"iopub.status.busy":"2024-07-02T21:52:42.574761Z","iopub.execute_input":"2024-07-02T21:52:42.575135Z","iopub.status.idle":"2024-07-02T21:52:42.584646Z","shell.execute_reply.started":"2024-07-02T21:52:42.575102Z","shell.execute_reply":"2024-07-02T21:52:42.583504Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def test_tflite(tflite_model = None, model_path = None, x_test = None, y_test = None, VERBOSE:int = 0):\n    if tflite_model is None and model_path is None:\n        raise ValueError(\"Either tf_model or model_path must be provided.\")\n    if tflite_model is not None and model_path is not None:\n        raise ValueError(\"Only one of tf_model or model_path must be provided.\")\n    if x_test is None or y_test is None:\n        raise ValueError(\"x_test and y_test must be provided for testing.\")\n\n    if tflite_model is not None:\n        tflite_model = tflite_model\n    if model_path is not None:\n        tflite_model = tf.keras.models.load_model(model_path)\n\n    tflite_interpreter = tf.lite.Interpreter(model_content = tflite_model)\n    tflite_interpreter.allocate_tensors()\n    test_accuracy, y_pred = custom_evaluate(tflite_interpreter, x_test, y_test)\n\n    if VERBOSE : print(f'TFLite test accuracy: {100*test_accuracy:.7f}%\\n')\n\n    return test_accuracy, y_pred, y_test","metadata":{"id":"GqLAh0MPRjob","executionInfo":{"status":"ok","timestamp":1719922174477,"user_tz":-330,"elapsed":38,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"execution":{"iopub.status.busy":"2024-07-02T21:52:48.022604Z","iopub.execute_input":"2024-07-02T21:52:48.023436Z","iopub.status.idle":"2024-07-02T21:52:48.030801Z","shell.execute_reply.started":"2024-07-02T21:52:48.023399Z","shell.execute_reply":"2024-07-02T21:52:48.029830Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def tf_to_tflite(model, model_path = None, quantization_type:str = 'DEFAULT', test = False, x_test = None, y_test = None, VERBOSE:int = 0):\n    \"\"\"\n    model_path : Given tflite model(string.tflite), this function will save the tflite model on the model path\n    test       : if test is true; give x_test and y_test and the function returns tflite_model, test_acc, y_pred, y_test\n    \"\"\"\n\n    # Convert the model to TF Lite format.\n    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n    if quantization_type == 'float16':\n        converter.target_spec.supported_types = [tf.float16]\n    tflite_model = converter.convert()\n\n    if model_path != None: save_tflite_model(tflite_model, model_path = model_path, VERBOSE = VERBOSE)\n\n    # return tflite_model, (test_acc, y_pred, y_test)\n    if test:\n        return tflite_model, test_tflite(tflite_model = tflite_model, x_test = x_test, y_test = y_test, VERBOSE = VERBOSE)\n    # returns only tflite model\n    else: return tflite_model","metadata":{"id":"T1QN5Y9U97a7","executionInfo":{"status":"ok","timestamp":1719922174477,"user_tz":-330,"elapsed":37,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"execution":{"iopub.status.busy":"2024-07-02T21:52:50.161242Z","iopub.execute_input":"2024-07-02T21:52:50.161900Z","iopub.status.idle":"2024-07-02T21:52:50.169320Z","shell.execute_reply.started":"2024-07-02T21:52:50.161865Z","shell.execute_reply":"2024-07-02T21:52:50.168264Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_tflite_model_precision(tflite_model):\n    # Load the TFLite model from path or model object\n    if isinstance(tflite_model, str):\n        interpreter = tf.lite.Interpreter(model_path=tflite_model)\n    elif isinstance(tflite_model, bytes):\n        interpreter = tf.lite.Interpreter(model_content=tflite_model)\n    else:\n        interpreter = tflite_model\n\n    interpreter.allocate_tensors()\n\n    # Get model details\n    tensor_details = interpreter.get_tensor_details()\n    operator_details = interpreter._get_ops_details()\n\n    # Dictionary to map tensor indices to their names and data types\n    tensor_info = {tensor['index']: {'name': tensor['name'], 'dtype': tensor['dtype']} for tensor in tensor_details}\n\n    # Collect precision information\n    precision_info = []\n\n    for op in operator_details:\n        op_name = op['op_name']\n        input_tensors = [tensor_info[tensor_idx] for tensor_idx in op['inputs'] if tensor_idx != -1]\n        output_tensors = [tensor_info[tensor_idx] for tensor_idx in op['outputs'] if tensor_idx != -1]\n        precision_info.append({\n            'op_name': op_name,\n            'inputs': input_tensors,\n            'outputs': output_tensors\n        })\n\n    return precision_info\n\ndef print_precision_info(precision_info):\n    for op_info in precision_info:\n        print(f\"Operator: {op_info['op_name']}\")\n        print(\"  Inputs:\")\n        for tensor in op_info['inputs']:\n            print(f\"    - Name: {tensor['name']}, DataType: {tensor['dtype']}\")\n        print(\"  Outputs:\")\n        for tensor in op_info['outputs']:\n            print(f\"    - Name: {tensor['name']}, DataType: {tensor['dtype']}\\n\")","metadata":{"id":"G66dH4lWS8LQ","executionInfo":{"status":"ok","timestamp":1719922174477,"user_tz":-330,"elapsed":37,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"execution":{"iopub.status.busy":"2024-07-02T21:52:51.453410Z","iopub.execute_input":"2024-07-02T21:52:51.454207Z","iopub.status.idle":"2024-07-02T21:52:51.466778Z","shell.execute_reply.started":"2024-07-02T21:52:51.454146Z","shell.execute_reply":"2024-07-02T21:52:51.465654Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def check_quantization_type(model = None, model_path = None):\n    # Load the model\n    if model_path is not None:\n        model = tf.keras.models.load_model(model_path)\n    if model is None and model_path is None:\n        raise ValueError(\"Either model or model_path must be provided.\")\n\n    # Get the model's input and output tensors\n    input_tensor = model.input\n    output_tensor = model.output\n\n    # Iterate through the layers and check their weights\n    for layer in model.layers:\n        weights = layer.get_weights()\n        for weight in weights:\n            weight_dtype = weight.dtype\n            if weight_dtype == tf.float32:\n                print(f\"Layer {layer.name} has float32 weights.\")\n            elif weight_dtype == tf.float16:\n                print(f\"Layer {layer.name} has float16 weights.\")\n            elif weight_dtype == tf.int8:\n                print(f\"Layer {layer.name} has int8 weights.\")\n            else:\n                print(f\"Layer {layer.name} has weights of type {weight_dtype}.\")\n\n    return True","metadata":{"id":"BwVef2W1VRRz","executionInfo":{"status":"ok","timestamp":1719922174477,"user_tz":-330,"elapsed":36,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"execution":{"iopub.status.busy":"2024-07-02T21:52:54.033802Z","iopub.execute_input":"2024-07-02T21:52:54.034608Z","iopub.status.idle":"2024-07-02T21:52:54.042729Z","shell.execute_reply.started":"2024-07-02T21:52:54.034561Z","shell.execute_reply":"2024-07-02T21:52:54.041604Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"vAHngCl5rFX0","executionInfo":{"status":"ok","timestamp":1719922174478,"user_tz":-330,"elapsed":37,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# trdML\nUsing traditional ML i.e. with whole dataset to a single to be trained on MNIST dataset","metadata":{"id":"1yxVpUfz0evs"}},{"cell_type":"markdown","source":"#### Loading MNIST","metadata":{"id":"jzyQIy9bQOiu"}},{"cell_type":"code","source":"# Load MNIST dataset\nmnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# # Normalize the input image so that each pixel value is between 0 to 1.\n# x_train, x_test = x_train.astype(np.float64), x_test.astype(np.float64)\nx_train = x_train / 255.0\nx_test = x_test / 255.0\n\n# # Reshape the data to include channel dimension\n# # This is important for testing on tflite so channel is required\nx_train = x_train[..., tf.newaxis]\nx_test = x_test[..., tf.newaxis]\n\nprint(f'Training data shape: {x_train.shape},  {type(x_train[0][0][0])}')\nprint(f'Test     data shape: {x_test.shape},  {type(x_test[0][0][0])}')\n\nprint(f'Label type(trn,tst): {type(y_train[0])}, {type(y_test[0])}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1450,"status":"ok","timestamp":1719922175892,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"},"user_tz":-330},"id":"xVvZEr4M0evt","outputId":"6aeca40a-b35a-4d94-d0c2-34ac5f0ecc45","execution":{"iopub.status.busy":"2024-07-02T21:54:27.670999Z","iopub.execute_input":"2024-07-02T21:54:27.671399Z","iopub.status.idle":"2024-07-02T21:54:28.330582Z","shell.execute_reply.started":"2024-07-02T21:54:27.671364Z","shell.execute_reply":"2024-07-02T21:54:28.329586Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 0s 0us/step\nTraining data shape: (60000, 28, 28, 1),  <class 'numpy.ndarray'>\nTest     data shape: (10000, 28, 28, 1),  <class 'numpy.ndarray'>\nLabel type(trn,tst): <class 'numpy.uint8'>, <class 'numpy.uint8'>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### trd Without quantization","metadata":{"id":"jbk5x7mH0evt"}},{"cell_type":"code","source":"EPOCHS, VERBOSE = 3, 1\n\nraw_model = create_model()\nraw_model = compile_model(raw_model)\n\nif(VERBOSE > 1): raw_model.summary()\nif(VERBOSE > 1): check_quantization_type(raw_model)\n\n# Train the no-quant model\nstime = time.time()\nraw_history = raw_model.fit(x_train[:], y_train[:], epochs=EPOCHS, batch_size=256, validation_split=0.2, verbose = VERBOSE)\n_, raw_test_acc = raw_model.evaluate(x_test, y_test, verbose=2)\netime = time.time()\n\ntrdTrainTime = etime - stime\nprint(f\"For training model for {EPOCHS} epochs had taken is {(etime-stime):.4f}s in  Traditional setup on MNIST\")\nprint(f\"Testing Inference on trained model; accuracy {100*raw_test_acc:.4f}% in  Traditional setup on MNIST\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103759,"status":"ok","timestamp":1719922452998,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"},"user_tz":-330},"id":"lZcmty650evt","outputId":"f4f3fe30-a65b-4518-dd4c-652c67afdd76","execution":{"iopub.status.busy":"2024-07-02T21:01:15.765471Z","iopub.execute_input":"2024-07-02T21:01:15.765757Z","iopub.status.idle":"2024-07-02T21:01:21.255766Z","shell.execute_reply.started":"2024-07-02T21:01:15.765732Z","shell.execute_reply":"2024-07-02T21:01:21.254869Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/3\n188/188 [==============================] - 3s 7ms/step - loss: 0.3781 - accuracy: 0.8965 - val_loss: 0.1483 - val_accuracy: 0.9597\nEpoch 2/3\n188/188 [==============================] - 1s 4ms/step - loss: 0.1216 - accuracy: 0.9641 - val_loss: 0.0974 - val_accuracy: 0.9722\nEpoch 3/3\n188/188 [==============================] - 1s 4ms/step - loss: 0.0790 - accuracy: 0.9780 - val_loss: 0.0713 - val_accuracy: 0.9783\n313/313 - 1s - loss: 0.0674 - accuracy: 0.9789 - 539ms/epoch - 2ms/step\nFor training model for 3 epochs had taken is 5.4185s in  Traditional setup on MNIST\nTesting Inference on trained model; accuracy 97.8900% in  Traditional setup on MNIST\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### Convert to tflite and test tflit model","metadata":{"id":"q9Coo7OXdeZX"}},{"cell_type":"code","source":"# # raw_model convert this tf model to tflite\nraw_tflite, report = tf_to_tflite(raw_model, model_path = \"raw_model.tflite\",\n                                quantization_type = 'DEFAULT',\n                                test = True, x_test = x_test, y_test = y_test,\n                                VERBOSE = 2)\n\nif VERBOSE > 1: print_precision_info(get_tflite_model_precision(raw_tflite))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aUla6DMnrnU","executionInfo":{"status":"ok","timestamp":1719922455500,"user_tz":-330,"elapsed":2545,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"outputId":"031a2fb9-a7c1-4e12-d320-4c7cd9dc24ca","execution":{"iopub.status.busy":"2024-07-02T21:01:21.257958Z","iopub.execute_input":"2024-07-02T21:01:21.258796Z","iopub.status.idle":"2024-07-02T21:01:23.195605Z","shell.execute_reply.started":"2024-07-02T21:01:21.258754Z","shell.execute_reply":"2024-07-02T21:01:23.194634Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Summary on the non-converted ops:\n---------------------------------\n * Accepted dialects: tfl, builtin, func\n * Non-Converted Ops: 6, Total Ops 16, % non-converted = 37.50 %\n * 6 ARITH ops\n\n- arith.constant:    6 occurrences  (f32: 5, i32: 1)\n\n\n\n  (f32: 1)\n  (f32: 2)\n  (f32: 1)\n  (uq_8: 1)\n  (f32: 1)\n  (f32: 1)\n","output_type":"stream"},{"name":"stdout","text":"Model saved as raw_model.tflite\nTFLite test accuracy: 97.8900000%\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train then quantization\n\nWith and without finetuning for one epoch and 10000 datapoints","metadata":{"id":"vSl0XOZCeweu"}},{"cell_type":"code","source":"import tensorflow_model_optimization as tfmot\nq_aware_model = tfmot.quantization.keras.quantize_model(raw_model)\nq_aware_model = compile_model(q_aware_model)\n\n\nif VERBOSE > 1: q_aware_model.summary()\nif VERBOSE > 1: check_quantization_type(q_aware_model)\n_, test_acc_qaware = q_aware_model.evaluate(x_test, y_test, verbose=2)\nprint(f\"Testing Inference on quant aware trained model; accuracy {100*test_acc_qaware:.4f}% in  Traditional setup on MNIST. \\n\",\n        \"Its sanity is argued, so it with grain of salt.\\n\")\n    \n\n    \n    \nFINETUNE = False\ntrain_quant_tflite, report = tf_to_tflite(q_aware_model,\n                                      model_path = f'train_quant_ftune{FINETUNE}.tflite',\n                                      quantization_type = 'float16',\n                                      test = True, x_test = x_test, y_test = y_test,\n                                      VERBOSE = 2)\n    \n    \n    \nFINETUNE = True\nif FINETUNE:\n    dataset_size_for_fine_tuning = 10\n    train_images_subset, train_labels_subset = x_train[0:dataset_size_for_fine_tuning], y_train[0:dataset_size_for_fine_tuning]\n    q_aware_model.fit(train_images_subset, train_labels_subset, batch_size=500, epochs=1, validation_split=0.1)\nprint()\ntrain_quant_finetuned_tflite, report = tf_to_tflite(q_aware_model,\n                                                    model_path = f'train_quant_ftune{FINETUNE}x{dataset_size_for_fine_tuning/1000}k.tflite',\n                                                    quantization_type = 'float16',\n                                                    test = True, x_test = x_test, y_test = y_test,\n                                                    VERBOSE = 2)\n\n\n    \nFINETUNE = True\nif FINETUNE:\n    dataset_size_for_fine_tuning = 10000\n    train_images_subset, train_labels_subset = x_train[0:dataset_size_for_fine_tuning], y_train[0:dataset_size_for_fine_tuning]\n    q_aware_model.fit(train_images_subset, train_labels_subset, batch_size=500, epochs=1, validation_split=0.1)\nprint()\ntrain_quant_finetuned_tflite, report = tf_to_tflite(q_aware_model,\n                                                    model_path = f'train_quant_ftune{FINETUNE}x{dataset_size_for_fine_tuning/1000}k.tflite',\n                                                    quantization_type = 'float16',\n                                                    test = True, x_test = x_test, y_test = y_test,\n                                                    VERBOSE = 2)\n\n# print_precision_info(get_tflite_model_precision(train_quant_finetuned_tflite)) ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3v4KpgcheXXx","executionInfo":{"status":"ok","timestamp":1719906756172,"user_tz":-330,"elapsed":7530,"user":{"displayName":"Vickey Kumar","userId":"02587512178673317676"}},"outputId":"c84bac2c-9e6b-4532-edf5-aec19572de1b","execution":{"iopub.status.busy":"2024-07-02T21:01:23.199726Z","iopub.execute_input":"2024-07-02T21:01:23.200062Z","iopub.status.idle":"2024-07-02T21:01:38.792333Z","shell.execute_reply.started":"2024-07-02T21:01:23.200034Z","shell.execute_reply":"2024-07-02T21:01:38.791371Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"313/313 - 2s - loss: 3.4472 - accuracy: 0.1135 - 2s/epoch - 6ms/step\nTesting Inference on quant aware trained model; accuracy 11.3500% in  Traditional setup on MNIST. \n Its sanity is argued, so it with grain of salt.\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\nSummary on the non-converted ops:\n---------------------------------\n * Accepted dialects: tfl, builtin, func\n * Non-Converted Ops: 1, Total Ops 18, % non-converted = 5.56 %\n * 1 ARITH ops\n\n- arith.constant:    1 occurrences  (i32: 1)\n\n\n\n  (uq_8: 1)\n  (f32: 1)\n  (uq_8: 2)\n  (uq_8: 1)\n  (uq_8: 3, uq_32: 3)\n  (uq_8: 1)\n  (uq_8: 1)\n  (uq_8: 1)\n","output_type":"stream"},{"name":"stdout","text":"Model saved as train_quant_ftuneFalse.tflite\nTFLite test accuracy: 11.3500000%\n\n1/1 [==============================] - 2s 2s/step - loss: 0.1539 - accuracy: 0.8889 - val_loss: 0.0404 - val_accuracy: 1.0000\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\nSummary on the non-converted ops:\n---------------------------------\n * Accepted dialects: tfl, builtin, func\n * Non-Converted Ops: 1, Total Ops 18, % non-converted = 5.56 %\n * 1 ARITH ops\n\n- arith.constant:    1 occurrences  (i32: 1)\n\n\n\n  (uq_8: 1)\n  (f32: 1)\n  (uq_8: 2)\n  (uq_8: 1)\n  (uq_8: 3, uq_32: 3)\n  (uq_8: 1)\n  (uq_8: 1)\n  (uq_8: 1)\n","output_type":"stream"},{"name":"stdout","text":"Model saved as train_quant_ftuneTruex0.01k.tflite\nTFLite test accuracy: 95.5800000%\n\n18/18 [==============================] - 0s 12ms/step - loss: 0.0917 - accuracy: 0.9780 - val_loss: 0.0592 - val_accuracy: 0.9850\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\nSummary on the non-converted ops:\n---------------------------------\n * Accepted dialects: tfl, builtin, func\n * Non-Converted Ops: 1, Total Ops 18, % non-converted = 5.56 %\n * 1 ARITH ops\n\n- arith.constant:    1 occurrences  (i32: 1)\n\n\n\n  (uq_8: 1)\n  (f32: 1)\n  (uq_8: 2)\n  (uq_8: 1)\n  (uq_8: 3, uq_32: 3)\n  (uq_8: 1)\n  (uq_8: 1)\n  (uq_8: 1)\n","output_type":"stream"},{"name":"stdout","text":"Model saved as train_quant_ftuneTruex10.0k.tflite\nTFLite test accuracy: 97.6600000%\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Quantization then train","metadata":{"id":"ECaH1xgfZ2Dw"}},{"cell_type":"code","source":"EPOCHS, VERBOSE = 3, 1\nPRECISION = 'float16'\n\n# On TPUs and CPUs, use 'mixed_bfloat16' instead\nfrom tensorflow.keras import mixed_precision\nif PRECISION == 'float16': mixed_precision.set_global_policy('mixed_float16')\n\n # Define the model\nquant_train_model = create_model(precision = PRECISION)\nquant_train_model = create_model()\nquant_train_model = compile_model(quant_train_model)\n\nq_aware_model = quant_train_model\nimport tensorflow_model_optimization as tfmot\nq_aware_model = tfmot.quantization.keras.quantize_model(quant_train_model)\nq_aware_model = compile_model(q_aware_model)\n\nif(VERBOSE > 1): q_aware_model.summary()\nif(VERBOSE > 1): check_quantization_type(q_aware_model)\n\n# Train the quant model\nstime = time.time()\nraw_history = q_aware_model.fit(x_train[:], y_train[:], epochs=EPOCHS, batch_size=128, validation_split=0.2, verbose = VERBOSE)\n_, quant_train_test_acc = q_aware_model.evaluate(x_test, y_test, verbose=2)\netime = time.time()\n\ntrdTrainTime = etime - stime\nprint(f\"For training model for {EPOCHS} epochs had taken is {(etime-stime):.4f}s in  Traditional setup on MNIST\")\nprint(f\"Testing Inference on trained model; accuracy {100*quant_train_test_acc:.4f}% in  Traditional setup on MNIST\")\n\n# tf.keras.mixed_precision.set_global_policy(None)","metadata":{"id":"hei13GNpZ6_u","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1719921067764,"user_tz":-330,"elapsed":628,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"outputId":"5b02464e-0bf1-44ce-bdc8-3a8043b5fa5a","execution":{"iopub.status.busy":"2024-07-02T21:01:38.793810Z","iopub.execute_input":"2024-07-02T21:01:38.794112Z","iopub.status.idle":"2024-07-02T21:01:48.950454Z","shell.execute_reply.started":"2024-07-02T21:01:38.794086Z","shell.execute_reply":"2024-07-02T21:01:48.949479Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/3\n375/375 [==============================] - 4s 7ms/step - loss: 0.2886 - accuracy: 0.9178 - val_loss: 0.1123 - val_accuracy: 0.9697\nEpoch 2/3\n375/375 [==============================] - 2s 5ms/step - loss: 0.0876 - accuracy: 0.9745 - val_loss: 0.0753 - val_accuracy: 0.9797\nEpoch 3/3\n375/375 [==============================] - 2s 5ms/step - loss: 0.0591 - accuracy: 0.9824 - val_loss: 0.0653 - val_accuracy: 0.9812\n313/313 - 1s - loss: 0.0570 - accuracy: 0.9811 - 694ms/epoch - 2ms/step\nFor training model for 3 epochs had taken is 9.7164s in  Traditional setup on MNIST\nTesting Inference on trained model; accuracy 98.1100% in  Traditional setup on MNIST\n","output_type":"stream"}]},{"cell_type":"code","source":"# if(VERBOSE > 1): q_aware_model.summary()\n# if(VERBOSE > 1): check_quantization_type(q_aware_model)\n\nFINETUNE = False\nquant_train_tflite, report = tf_to_tflite(model = q_aware_model,\n                                      model_path = f'quant_train_ftune{FINETUNE}.tflite',\n                                      quantization_type = 'float16',\n                                      test = True, x_test = x_test, y_test = y_test,\n                                      VERBOSE = 2)\n\nFINETUNE = True\nif FINETUNE:\n    dataset_size_for_fine_tuning = 10000\n    train_images_subset, train_labels_subset = x_train[0:dataset_size_for_fine_tuning], y_train[0:dataset_size_for_fine_tuning]\n    q_aware_model.fit(train_images_subset, train_labels_subset, batch_size=512, epochs=1, validation_split=0.1)\n\nquant_train_finetuned_tflite, report = tf_to_tflite(model = q_aware_model,\n                                      model_path = f'quant_train_ftune{FINETUNE}x{dataset_size_for_fine_tuning/1000}k.tflite',\n                                      quantization_type = 'float16',\n                                      test = True, x_test = x_test, y_test = y_test,\n                                      VERBOSE = 2)","metadata":{"id":"mVJLJGKuadgD","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1719914892660,"user_tz":-330,"elapsed":1933,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"outputId":"0a84c961-ba79-4330-9880-3a2bffd09ed1","execution":{"iopub.status.busy":"2024-07-02T21:01:48.951605Z","iopub.execute_input":"2024-07-02T21:01:48.951908Z","iopub.status.idle":"2024-07-02T21:01:57.397442Z","shell.execute_reply.started":"2024-07-02T21:01:48.951880Z","shell.execute_reply":"2024-07-02T21:01:57.396477Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\nSummary on the non-converted ops:\n---------------------------------\n * Accepted dialects: tfl, builtin, func\n * Non-Converted Ops: 1, Total Ops 18, % non-converted = 5.56 %\n * 1 ARITH ops\n\n- arith.constant:    1 occurrences  (i32: 1)\n\n\n\n  (uq_8: 1)\n  (f32: 1)\n  (uq_8: 2)\n  (uq_8: 1)\n  (uq_8: 3, uq_32: 3)\n  (uq_8: 1)\n  (uq_8: 1)\n  (uq_8: 1)\n","output_type":"stream"},{"name":"stdout","text":"Model saved as quant_train_ftuneFalse.tflite\nTFLite test accuracy: 98.1100000%\n\n18/18 [==============================] - 1s 19ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 0.0322 - val_accuracy: 0.9880\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\nSummary on the non-converted ops:\n---------------------------------\n * Accepted dialects: tfl, builtin, func\n * Non-Converted Ops: 1, Total Ops 18, % non-converted = 5.56 %\n * 1 ARITH ops\n\n- arith.constant:    1 occurrences  (i32: 1)\n\n\n\n  (uq_8: 1)\n  (f32: 1)\n  (uq_8: 2)\n  (uq_8: 1)\n  (uq_8: 3, uq_32: 3)\n  (uq_8: 1)\n  (uq_8: 1)\n  (uq_8: 1)\n","output_type":"stream"},{"name":"stdout","text":"Model saved as quant_train_ftuneTruex10.0k.tflite\nTFLite test accuracy: 98.3300000%\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### Checking Quantization of tflite model","metadata":{}},{"cell_type":"code","source":"tflite_model_paths = ['raw_model.tflite','train_quant_ftuneFalse.tflite', f'train_quant_ftuneTruex{dataset_size_for_fine_tuning/1000}k.tflite',\n                      'quant_train_ftuneFalse.tflite', f'quant_train_ftuneTruex{dataset_size_for_fine_tuning/1000}k.tflite']\n\nimport os\nfor tflite_model_path in tflite_model_paths[:]:\n    print(f'\\n\\n{tflite_model_path}')\n    print_precision_info(get_tflite_model_precision(tflite_model_path))\n    \n    # Get the size of the model file\n    model_size_in_bytes = os.path.getsize(tflite_model_path)\n    model_size_in_mb = model_size_in_bytes / float(2**20)\n\n    print(f\"Model = {tflite_model_path} size in MB: {model_size_in_mb:.2f}\")\n    \n# import tempfile\n# import os\n\n# # Create float TFLite model.\n# float_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n# float_tflite_model = float_converter.convert()\n\n# # Measure sizes of models.\n# _, float_file = tempfile.mkstemp('.tflite')\n# _, quant_file = tempfile.mkstemp('.tflite')\n\n# with open(quant_file, 'wb') as f:\n#   f.write(quantized_tflite_model)\n\n# with open(float_file, 'wb') as f:\n#   f.write(float_tflite_model)\n\n# print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))\n# print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))","metadata":{"execution":{"iopub.status.busy":"2024-07-02T21:03:16.498350Z","iopub.execute_input":"2024-07-02T21:03:16.499278Z","iopub.status.idle":"2024-07-02T21:03:16.507494Z","shell.execute_reply.started":"2024-07-02T21:03:16.499244Z","shell.execute_reply":"2024-07-02T21:03:16.506383Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"\n\nraw_model.tflite\nModel = raw_model.tflite size in MB: 0.34\n\n\ntrain_quant_ftuneFalse.tflite\nModel = train_quant_ftuneFalse.tflite size in MB: 0.34\n\n\ntrain_quant_ftuneTruex10.0k.tflite\nModel = train_quant_ftuneTruex10.0k.tflite size in MB: 0.34\n\n\nquant_train_ftuneFalse.tflite\nModel = quant_train_ftuneFalse.tflite size in MB: 0.34\n\n\nquant_train_ftuneTruex10.0k.tflite\nModel = quant_train_ftuneTruex10.0k.tflite size in MB: 0.34\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Quant Ablation\n\nBaseline test accuracy: 98.170% <br>\nQuant without finetune test accuracy: 98.390% <br>\nQuant with    finetune test accuracy: 98.310% \t\t[on 1000 datapoints] <br>\nQuant with    finetune TFLite test accuracy: 98.310% <br>","metadata":{"id":"kHok7c7o0evu"}},{"cell_type":"code","source":"# import warnings\n# warnings.filterwarnings(\"ignore\")\n\n# _, baseline_model_accuracy = model.evaluate(\n#     x_test, y_test, verbose=0)\n\n# fine_tune_datapoints = 10000\n# quantization_types = ['DEFAULT', 'float32', 'uint8', 'int8',] # 'int16'\n# for quantization_type in quantization_types[1:2]:\n#     print(quantization_type)\n#     # Quantize aware model; Quantize the model;;\n#     q_aware_model = apply_quantization_to_model(model)\n#     _, q_aware_model_without_finetune_accuracy = q_aware_model.evaluate(\n#        x_test, y_test, verbose=0)\n\n#     x_train_quant, y_train_quant = x_train[:fine_tune_datapoints].astype(np.float32), y_train[0:fine_tune_datapoints]\n#     q_aware_history = q_aware_model.fit(x_train_quant, y_train_quant, epochs=1,\n#                                         batch_size=64,\n#                                         validation_split=0.2,\n#                                         verbose = 0)\n\n#     _, q_aware_model_accuracy = q_aware_model.evaluate(\n#         x_test, y_test, verbose=0)\n\n#     # Example: Convert to different quantization types\n#     quantization_type = quantization_type\n#     quantized_tflite_model = convert_to_tflite(model = q_aware_model, dataset=x_train, quantization_type = quantization_type)\n#     quantized_tflite_interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n#     quantized_tflite_interpreter.allocate_tensors()\n#     quantized_tflite_test_accuracy = custom_evaluate(quantized_tflite_interpreter, x_test, y_test,quantization_type)\n\n#     print(f'Baseline test accuracy: {100*baseline_model_accuracy:.7f}%')\n#     print(f'{quantization_type} Quant without finetune test accuracy: {100*q_aware_model_without_finetune_accuracy:.7f}%')\n#     print(f'{quantization_type} Quant with    finetune test accuracy: {100*q_aware_model_accuracy:.7f}% \\t\\t[on {fine_tune_datapoints} datapoints]')\n#     print(f'{quantization_type} Quant with    finetune TFLite test accuracy: {100*quantized_tflite_test_accuracy:.7f}%')","metadata":{"id":"q44owKz50evu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pruning","metadata":{"id":"TFnvCm1WvLrG"}},{"cell_type":"markdown","source":"### Aware","metadata":{"id":"Inx5HtPgvUQB"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_model_optimization as tfmot\nimport time\n\n# Define constants\nEPOCHS = 1\nVERBOSE = 2\n\n# Define the model architecture\nmodel_noQuant  = keras.Sequential([\n    keras.layers.InputLayer(input_shape=(28, 28, 1)),\n    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    keras.layers.Flatten(),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(10, activation='softmax')\n])\n# Apply pruning\npruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n    initial_sparsity=0.0,\n    final_sparsity=0.5,\n    begin_step=0,\n    end_step=np.ceil(x_train.shape[0] / 64).astype(np.int32) * EPOCHS\n)\n\npruned_model = tfmot.sparsity.keras.prune_low_magnitude(model_noQuant, pruning_schedule=pruning_schedule)\n\n# Compile the model\npruned_model.compile(optimizer='adam',\n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n              metrics=['accuracy'])\n\npruned_model.summary()\n\n# Define callbacks for pruning\ncallbacks = [\n    tfmot.sparsity.keras.UpdatePruningStep(),\n    tfmot.sparsity.keras.PruningSummaries(log_dir='./pruning_logs')\n]\n\n# Train the pruned model\nstime = time.time()\nhistory_pruned = pruned_model.fit(x_train[:], y_train[:], epochs=EPOCHS, batch_size=64, validation_split=0.2, verbose=VERBOSE, callbacks=callbacks)\n_, test_acc_pruned = pruned_model.evaluate(x_test, y_test, verbose=2)\netime = time.time()\n\nprunedTrainTime = etime - stime\nprint(f\"For training pruned model for {EPOCHS} epochs had taken is {(etime-stime):.4f}s on MNIST\")\nprint(f\"Testing Inference on pruned model; accuracy {100*test_acc_pruned:.4f}% on MNIST\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T21:54:34.211326Z","iopub.execute_input":"2024-07-02T21:54:34.212064Z","iopub.status.idle":"2024-07-02T21:54:49.820361Z","shell.execute_reply.started":"2024-07-02T21:54:34.212030Z","shell.execute_reply":"2024-07-02T21:54:49.818615Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n prune_low_magnitude_conv2d  (None, 26, 26, 32)        610       \n _2 (PruneLowMagnitude)                                          \n                                                                 \n prune_low_magnitude_max_po  (None, 13, 13, 32)        1         \n oling2d_2 (PruneLowMagnitu                                      \n de)                                                             \n                                                                 \n prune_low_magnitude_flatte  (None, 5408)              1         \n n_2 (PruneLowMagnitude)                                         \n                                                                 \n prune_low_magnitude_dense_  (None, 64)                692290    \n 4 (PruneLowMagnitude)                                           \n                                                                 \n prune_low_magnitude_dense_  (None, 10)                1292      \n 5 (PruneLowMagnitude)                                           \n                                                                 \n=================================================================\nTotal params: 694194 (2.65 MB)\nTrainable params: 347146 (1.32 MB)\nNon-trainable params: 347048 (1.32 MB)\n_________________________________________________________________\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Train the pruned model\u001b[39;00m\n\u001b[1;32m     43\u001b[0m stime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 44\u001b[0m history_pruned \u001b[38;5;241m=\u001b[39m \u001b[43mpruned_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVERBOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m _, test_acc_pruned \u001b[38;5;241m=\u001b[39m pruned_model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     46\u001b[0m etime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/engine/training.py:1804\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1798\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1801\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1802\u001b[0m ):\n\u001b[1;32m   1803\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1804\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1806\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 888\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    891\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n","File \u001b[0;32m/tmp/__autograph_generated_file00qmi61o.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n","File \u001b[0;32m/tmp/__autograph_generated_filee4w_kjk8.py:45\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m     43\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mjit_compile, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_step\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m data \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mnext\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(iterator),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(reduce_per_replica), (ag__\u001b[38;5;241m.\u001b[39mld(outputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_strategy), \u001b[38;5;28mdict\u001b[39m(reduction\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdistribute_reduction_method), fscope)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[38;5;66;03m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4068\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 4069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/tmp/__autograph_generated_filee4w_kjk8.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     16\u001b[0m do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m retval__1 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcontrol_dependencies(ag__\u001b[38;5;241m.\u001b[39mld(_minimum_control_deps)(ag__\u001b[38;5;241m.\u001b[39mld(outputs))):\n\u001b[1;32m     20\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(model)\u001b[38;5;241m.\u001b[39m_train_counter\u001b[38;5;241m.\u001b[39massign_add, (\u001b[38;5;241m1\u001b[39m,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope_1)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n","File \u001b[0;32m/tmp/__autograph_generated_fileqc3d01di.py:38\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     37\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n\u001b[0;32m---> 38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_validate_target_and_loss, (ag__\u001b[38;5;241m.\u001b[39mld(y), ag__\u001b[38;5;241m.\u001b[39mld(loss)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     40\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28mdict\u001b[39m(tape\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(tape)), fscope)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n","File \u001b[0;32m/tmp/__autograph_generated_filev55frnk9.py:63\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__compute_loss\u001b[0;34m(self, x, y, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiled_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mregularization_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:427\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m   program_ctx \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mProgramContext(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m--> 427\u001b[0m   converted_f \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_actual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_entity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogram_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mhas_verbosity(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    429\u001b[0m     _log_callargs(converted_f, effective_args, kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:269\u001b[0m, in \u001b[0;36m_convert_actual\u001b[0;34m(entity, program_ctx)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(entity, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    265\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot apply autograph to a function that doesn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    266\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpose a __code__ object. If this is a @tf.function,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    267\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m try passing f.python_function instead.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m transformed, module, source_map \u001b[38;5;241m=\u001b[39m \u001b[43m_TRANSPILER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogram_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformed, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_module\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformed, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_source_map\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/transpiler.py:282\u001b[0m, in \u001b[0;36mGenericTranspiler.transform\u001b[0;34m(self, obj, user_context)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transforms a Python object.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mUsers typically call this method.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m  NotImplementedError: if the type of obj is not handled.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj):\n\u001b[0;32m--> 282\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNon-function: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(obj)))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/transpiler.py:466\u001b[0m, in \u001b[0;36mPyToPy.transform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    464\u001b[0m logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not cached for subkey \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, fn, cache_subkey)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Confusing overloading pattern. Fix.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m nodes, ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPyToPy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nodes, gast\u001b[38;5;241m.\u001b[39mLambda):\n\u001b[1;32m    469\u001b[0m   nodes \u001b[38;5;241m=\u001b[39m gast\u001b[38;5;241m.\u001b[39mAssign(\n\u001b[1;32m    470\u001b[0m       targets\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    471\u001b[0m           gast\u001b[38;5;241m.\u001b[39mName(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m       ],\n\u001b[1;32m    477\u001b[0m       value\u001b[38;5;241m=\u001b[39mnodes)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/transpiler.py:359\u001b[0m, in \u001b[0;36mGenericTranspiler.transform_function\u001b[0;34m(self, fn, user_context)\u001b[0m\n\u001b[1;32m    356\u001b[0m context \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mContext(entity_info, namer, user_context)\n\u001b[1;32m    358\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_erase_arg_defaults(node)\n\u001b[0;32m--> 359\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_ast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result, context\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:253\u001b[0m, in \u001b[0;36mPyToTF.transform_ast\u001b[0;34m(self, node, ctx)\u001b[0m\n\u001b[1;32m    251\u001b[0m   node \u001b[38;5;241m=\u001b[39m slices\u001b[38;5;241m.\u001b[39mtransform(node, ctx)\n\u001b[1;32m    252\u001b[0m node \u001b[38;5;241m=\u001b[39m call_trees\u001b[38;5;241m.\u001b[39mtransform(node, ctx)\n\u001b[0;32m--> 253\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[43mcontrol_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m node \u001b[38;5;241m=\u001b[39m conditional_expressions\u001b[38;5;241m.\u001b[39mtransform(node, ctx)\n\u001b[1;32m    255\u001b[0m node \u001b[38;5;241m=\u001b[39m logical_expressions\u001b[38;5;241m.\u001b[39mtransform(node, ctx)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/converters/control_flow.py:408\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(node, ctx)\u001b[0m\n\u001b[1;32m    406\u001b[0m node \u001b[38;5;241m=\u001b[39m qual_names\u001b[38;5;241m.\u001b[39mresolve(node)\n\u001b[1;32m    407\u001b[0m node \u001b[38;5;241m=\u001b[39m activity\u001b[38;5;241m.\u001b[39mresolve(node, ctx, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 408\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[43mreaching_definitions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m node \u001b[38;5;241m=\u001b[39m reaching_fndefs\u001b[38;5;241m.\u001b[39mresolve(node, ctx, graphs)\n\u001b[1;32m    410\u001b[0m node \u001b[38;5;241m=\u001b[39m liveness\u001b[38;5;241m.\u001b[39mresolve(node, ctx, graphs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/reaching_definitions.py:287\u001b[0m, in \u001b[0;36mresolve\u001b[0;34m(node, source_info, graphs, definition_factory)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resolves reaching definitions for each symbol.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m  ast.AST\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    286\u001b[0m visitor \u001b[38;5;241m=\u001b[39m TreeAnnotator(source_info, graphs, definition_factory)\n\u001b[0;32m--> 287\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[43mvisitor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/reaching_definitions.py:269\u001b[0m, in \u001b[0;36mTreeAnnotator.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_analyzer\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m    268\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_cfg_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_analyzer\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mindex[node]\n\u001b[0;32m--> 269\u001b[0m node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTreeAnnotator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_cfg_node \u001b[38;5;241m=\u001b[39m parent\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m node\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/transformer.py:441\u001b[0m, in \u001b[0;36mBase.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processing_expr_node:\n\u001b[1;32m    439\u001b[0m   entry_expr_value \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m--> 441\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Adjust for consistency: replacing the value of an Expr with\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# an Assign node removes the need for the Expr node.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (processing_expr_node \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, gast\u001b[38;5;241m.\u001b[39mExpr) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     (result\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m entry_expr_value)):\n\u001b[1;32m    447\u001b[0m   \u001b[38;5;66;03m# When the replacement is a list, it is assumed that the list came\u001b[39;00m\n\u001b[1;32m    448\u001b[0m   \u001b[38;5;66;03m# from a template that contained a number of statements, which\u001b[39;00m\n\u001b[1;32m    449\u001b[0m   \u001b[38;5;66;03m# themselves are standalone and don't require an enclosing Expr.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/ast.py:418\u001b[0m, in \u001b[0;36mNodeVisitor.visit\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    416\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m node\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    417\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneric_visit)\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/reaching_definitions.py:190\u001b[0m, in \u001b[0;36mTreeAnnotator.visit_FunctionDef\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    187\u001b[0m subgraph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraphs[node]\n\u001b[1;32m    189\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m Analyzer(subgraph, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefinition_factory)\n\u001b[0;32m--> 190\u001b[0m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Recursively process any remaining subfunctions.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_analyzer \u001b[38;5;241m=\u001b[39m analyzer\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/cfg.py:239\u001b[0m, in \u001b[0;36mGraphVisitor.visit_forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_visit_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_WalkMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFORWARD\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/cfg.py:227\u001b[0m, in \u001b[0;36mGraphVisitor._visit_internal\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    224\u001b[0m node \u001b[38;5;241m=\u001b[39m open_\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    225\u001b[0m closed\u001b[38;5;241m.\u001b[39madd(node)\n\u001b[0;32m--> 227\u001b[0m should_revisit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m _WalkMode\u001b[38;5;241m.\u001b[39mFORWARD:\n\u001b[1;32m    230\u001b[0m   children \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mnext\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/reaching_definitions.py:150\u001b[0m, in \u001b[0;36mAnalyzer.visit_node\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    148\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_map[node]\n\u001b[1;32m    149\u001b[0m kill \u001b[38;5;241m=\u001b[39m node_scope\u001b[38;5;241m.\u001b[39mmodified \u001b[38;5;241m|\u001b[39m node_scope\u001b[38;5;241m.\u001b[39mdeleted\n\u001b[0;32m--> 150\u001b[0m defs_out \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefs_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_map[node]\n\u001b[1;32m    153\u001b[0m defs_out \u001b[38;5;241m=\u001b[39m gen \u001b[38;5;241m|\u001b[39m (defs_in \u001b[38;5;241m-\u001b[39m kill)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/reaching_definitions.py:94\u001b[0m, in \u001b[0;36m_NodeState.__or__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     92\u001b[0m     result\u001b[38;5;241m.\u001b[39mvalue[s]\u001b[38;5;241m.\u001b[39mupdate(other_infos)\n\u001b[1;32m     93\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     result\u001b[38;5;241m.\u001b[39mvalue[s] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(other_infos)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import time\nimport numpy as np# Import the 'models' module from Keras\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\ntry:\n    import tensorflow_model_optimization as tfmot\nexcept:\n    !pip -q install tensorflow-model-optimization\n    import tensorflow_model_optimization as tfmot\n\nimport time\n\n# Define constants\nEPOCHS = 3\nVERBOSE = 2\n\n# Apply pruning\npruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n    initial_sparsity=0.5,\n    final_sparsity=0.8,\n    begin_step=0,\n    end_step=np.ceil(x_train.shape[0] / 64).astype(np.int32) * EPOCHS\n)\n# Define callbacks for pruning\ncallbacks = [\n    tfmot.sparsity.keras.UpdatePruningStep(),\n    tfmot.sparsity.keras.PruningSummaries(log_dir='./pruning_logs')\n]\n\n\nraw_model = create_model()\nraw_model = compile_model(raw_model)\npruned_model = tfmot.sparsity.keras.prune_low_magnitude(raw_model, pruning_schedule=pruning_schedule)\npruned_model = compile_model(pruned_model)\n\n# if VERBOSE >= 2: raw_model.summary()\n# if VERBOSE >= 2: pruned_model.summary()\n\n# Train baseline\nstime = time.time()\nraw_history = raw_model.fit(x_train[:], y_train[:], epochs=EPOCHS, batch_size=64, validation_split=0.2, verbose=VERBOSE)\netime = time.time()\nprint(f\"For training raw baseline model for {EPOCHS} epochs had taken is {(etime-stime):.4f}s on MNIST\")\n\n\n# Train the pruned model\nstime = time.time()\npruned_history = pruned_model.fit(x_train[:], y_train[:], epochs=EPOCHS, batch_size=64, validation_split=0.2, verbose=VERBOSE, callbacks=callbacks)\netime = time.time()\nprint(f\"For training prune baseline model for {EPOCHS} epochs had taken is {(etime-stime):.4f}s on MNIST\")\n\n\n\n_, raw_test_acc = raw_model.evaluate(x_test, y_test, verbose=2)\n_, pruned_test_acc = pruned_model.evaluate(x_test, y_test, verbose=2)\nprint(f\"Testing Inference on raw model; accuracy {100*raw_test_acc:.4f}% on MNIST\")\nprint(f\"Testing Inference on pruned model; accuracy {100*pruned_test_acc:.4f}% on MNIST\")","metadata":{"execution":{"iopub.status.busy":"2024-07-02T22:01:39.892777Z","iopub.execute_input":"2024-07-02T22:01:39.893641Z","iopub.status.idle":"2024-07-02T22:02:02.653062Z","shell.execute_reply.started":"2024-07-02T22:01:39.893592Z","shell.execute_reply":"2024-07-02T22:02:02.651970Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 1/3\n750/750 - 4s - loss: 0.2342 - accuracy: 0.9338 - val_loss: 0.0953 - val_accuracy: 0.9725 - 4s/epoch - 6ms/step\nEpoch 2/3\n750/750 - 2s - loss: 0.0772 - accuracy: 0.9772 - val_loss: 0.0766 - val_accuracy: 0.9768 - 2s/epoch - 3ms/step\nEpoch 3/3\n750/750 - 2s - loss: 0.0528 - accuracy: 0.9837 - val_loss: 0.0645 - val_accuracy: 0.9811 - 2s/epoch - 3ms/step\nFor training raw baseline model for 3 epochs had taken is 8.7334s on MNIST\nEpoch 1/3\n750/750 - 6s - loss: 0.0471 - accuracy: 0.9861 - val_loss: 0.0641 - val_accuracy: 0.9813 - 6s/epoch - 8ms/step\nEpoch 2/3\n750/750 - 3s - loss: 0.0412 - accuracy: 0.9887 - val_loss: 0.0964 - val_accuracy: 0.9711 - 3s/epoch - 4ms/step\nEpoch 3/3\n750/750 - 3s - loss: 0.0349 - accuracy: 0.9904 - val_loss: 0.0564 - val_accuracy: 0.9849 - 3s/epoch - 4ms/step\nFor training prune baseline model for 3 epochs had taken is 12.4445s on MNIST\n313/313 - 1s - loss: 0.0512 - accuracy: 0.9844 - 571ms/epoch - 2ms/step\n313/313 - 1s - loss: 0.0512 - accuracy: 0.9844 - 555ms/epoch - 2ms/step\nTesting Inference on raw model; accuracy 98.4400% on MNIST\nTesting Inference on pruned model; accuracy 98.4400% on MNIST\n","output_type":"stream"}]},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow import keras\n# import tensorflow_model_optimization as tfmot\n# import time\n\n# Define constants\nEPOCHS = 3\nVERBOSE = 2\nSAVE_MODEL = 1\n\n# Load or define the dataset\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\nx_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\nx_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n\n# Define the original model architecture\nmodel_noQuant = create_model()\nmodel_noQuant = compile_model(model_noQuant)\n\n# Train the original model\nstime = time.time()\nhistory_False = model_noQuant.fit(x_train, y_train, epochs=EPOCHS, batch_size=64, validation_split=0.2, verbose=VERBOSE)\netime = time.time()\n\n_, test_acc_False = model_noQuant.evaluate(x_test, y_test, verbose=VERBOSE)\nprint(f\"Training model for {EPOCHS} epochs took {(etime-stime):.4f}s in the traditional setup on MNIST\")\nprint(f\"Testing inference on trained model; accuracy {100*test_acc_False:.4f}% in the traditional setup on MNIST\")\n\n\n\n# Post-training pruning\nprune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n\npruning_params = {\n    'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=0.5, begin_step=0, frequency=1)\n}\npruned_model = prune_low_magnitude(model_noQuant, **pruning_params)\npruned_model.compile(optimizer='adam',\n                     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n                     metrics=['accuracy'])\n\n\n\n\n# Reporting without finetuning\n_, test_acc_without_fine = pruned_model.evaluate(x_test, y_test, verbose=VERBOSE)\nprint(f\"Testing inference on trained then pruned model; accuracy {100*test_acc_without_fine:.4f}% in the traditional setup on MNIST\")\n\n\n\n\n\n\n# Fine-tune the pruned model\ncallbacks = [\n    tfmot.sparsity.keras.UpdatePruningStep(),\n    tfmot.sparsity.keras.PruningSummaries(log_dir='./pruning_logs')\n]\n\nstime = time.time()\nhistory_pruned = pruned_model.fit(x_train, y_train, epochs=1, batch_size=64, validation_split=0.2, verbose=VERBOSE, callbacks=callbacks)\netime = time.time()\n_, test_acc_pruned = pruned_model.evaluate(x_test, y_test, verbose=VERBOSE)\nprint(f\"Fine-tuning pruned model for {EPOCHS} epochs took {(etime-stime):.4f}s on MNIST\")\nprint(f\"Testing inference on pruned model with finetuning ; accuracy {100*test_acc_pruned:.4f}% on MNIST\")\n\n# Strip pruning wrappers from the model\nfinal_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n\nif SAVE_MODEL:\n    final_model.save('pruned_model.h5')\n    model_noQuant.save('model_noQuant.h5')\n    print(\"Pruned model saved to 'pruned_model.h5'\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-snE56LIwgew","executionInfo":{"status":"ok","timestamp":1719476738042,"user_tz":-330,"elapsed":27974,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"outputId":"96344f51-bd2f-4b76-c211-f054e19b67c0","execution":{"iopub.status.busy":"2024-07-02T22:27:37.744516Z","iopub.execute_input":"2024-07-02T22:27:37.744962Z","iopub.status.idle":"2024-07-02T22:27:57.701319Z","shell.execute_reply.started":"2024-07-02T22:27:37.744929Z","shell.execute_reply":"2024-07-02T22:27:57.700345Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/3\n750/750 - 5s - loss: 0.2452 - accuracy: 0.9296 - val_loss: 0.0981 - val_accuracy: 0.9722 - 5s/epoch - 7ms/step\nEpoch 2/3\n750/750 - 2s - loss: 0.0784 - accuracy: 0.9767 - val_loss: 0.0729 - val_accuracy: 0.9790 - 2s/epoch - 3ms/step\nEpoch 3/3\n750/750 - 2s - loss: 0.0528 - accuracy: 0.9847 - val_loss: 0.0582 - val_accuracy: 0.9834 - 2s/epoch - 3ms/step\n313/313 - 1s - loss: 0.0487 - accuracy: 0.9845 - 705ms/epoch - 2ms/step\nTraining model for 3 epochs took 10.0762s in the traditional setup on MNIST\nTesting inference on trained model; accuracy 98.4500% in the traditional setup on MNIST\n313/313 - 2s - loss: 0.0487 - accuracy: 0.9845 - 2s/epoch - 5ms/step\nTesting inference on trained then pruned model; accuracy 98.4500% in the traditional setup on MNIST\n750/750 - 6s - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.0629 - val_accuracy: 0.9806 - 6s/epoch - 8ms/step\n313/313 - 1s - loss: 0.0560 - accuracy: 0.9823 - 571ms/epoch - 2ms/step\nFine-tuning pruned model for 3 epochs took 6.9222s on MNIST\nTesting inference on pruned model with finetuning ; accuracy 98.2300% on MNIST\nPruned model saved to 'pruned_model.h5'\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"}]},{"cell_type":"code","source":"history = history_pruned\nmodel = pruned_model","metadata":{"id":"l_GZ9r1cv6Cd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizations","metadata":{"id":"GUMm_YR10evv"}},{"cell_type":"code","source":"# Plotting in a single figure with subplots\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))\n\n# Plot training & validation loss values\nax[0].plot(history.history['loss'], label='Train Loss', marker=\"+\")\nax[0].plot(history.history['val_loss'], label='Validation Loss')\nax[0].set_title('Trd Model Loss')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\nax[0].legend(loc='upper right')\n\n# Plot training & validation accuracy values\nax[1].plot(history.history['accuracy'], label='Train Accuracy', marker=\"+\")\nax[1].plot(history.history['val_accuracy'], label='Validation Accuracy')\nax[1].set_title('Trd Model Accuracy')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nax[1].legend(loc='lower right')\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"cszF3EN50evv","outputId":"8bf9744b-5793-4593-f8ab-47379d25142f","colab":{"base_uri":"https://localhost:8080/","height":599},"executionInfo":{"status":"ok","timestamp":1719475945300,"user_tz":-330,"elapsed":1016,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n\n# Predict the labels\ny_pred = model.predict(x_test)\ny_pred_classes = y_pred.argmax(axis=1)\n\n# Print the classification report\nprint(f'Test accuracy: {test_acc}')\nprint(classification_report(y_test, y_pred_classes))\n\nprint('Confusion Matrix:')\nprint(confusion_matrix(y_test, y_pred_classes))","metadata":{"id":"6XQofmWn0evv","outputId":"99ce2339-ca04-4d3d-9f70-8775ed8d230a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719475980882,"user_tz":-330,"elapsed":6247,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# fedML","metadata":{"id":"LHXBelq20evw"}},{"cell_type":"code","source":"# Number of workers\nN_WORKERS = 4\n\n# Federated learning parameters\nEPOCHS = 3\nSAVE_MODEL = 0\nEPOCHS_WITHIN = 1\n\nVERBOSE = 2 # more the VERBOSE more the things about model is exposed\nVISUALIZE_WEIGHT_AFTER = 2","metadata":{"id":"vzUMx2YY0evw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Load MNIST dataset\nmnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\ntrain_subset_length = 60000             # For demonstration purposes use less\nx_train = x_train[:train_subset_length]\ny_train = y_train[:train_subset_length]\n\n# Normalize the data\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\n\n# # Reshape the data to include channel dimension\n# x_train = x_train[..., tf.newaxis]\n# x_test = x_test[..., tf.newaxis]\n\n# Split the data into training and validation sets\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=1/6, random_state=42)\n\n# Split the training data among workers\nx_train_splits = np.array_split(x_train, N_WORKERS)\ny_train_splits = np.array_split(y_train, N_WORKERS)\n\n# Print the shapes to verify\nfor i in range(N_WORKERS):\n    print(f'Worker {i+1} - Training data shape: {x_train_splits[i].shape}')\nprint('--------------------------------------------------')\nprint(f'Total Training data shape: {x_train.shape}')\nprint(f'Validation data shape: {x_val.shape}')\nprint(f'Test data shape: {x_test.shape}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":957,"status":"ok","timestamp":1719568229199,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"},"user_tz":-330},"id":"peuAhwJt0evw","outputId":"0429ff79-881d-4a54-d224-12e82a475407"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Quantized training with pruning flows","metadata":{"id":"RYNk3oOw4wVm"}},{"cell_type":"code","source":"# # Initialize models for each worker\n# models = [create_model() for _ in range(N_WORKERS)]\n# pruned_models = [prune_model(model) for model in models]\n\n# # Initialize metrics\n# worker_train_losses = [[] for _ in range(N_WORKERS)]\n# worker_val_losses = [[] for _ in range(N_WORKERS)]\n# worker_train_accuracies = [[] for _ in range(N_WORKERS)]\n# worker_val_accuracies = [[] for _ in range(N_WORKERS)]\n# worker_weights = [[] for _ in range(N_WORKERS)]\n\n# # 0.0 Training the models (fedML (none))\n# fedTrainTime = 0\n# for epoch in range(EPOCHS):\n#     fedTrainTime1 = 0\n#     worker_histories = []\n#     print(f'Epoch {epoch+1}/{EPOCHS}')\n\n#     # Train each worker's model for {EPOCHS_WITHIN} epochs\n#     for i in range(N_WORKERS):\n#         stime = time.time()\n#         history = models[i].fit(x_train_splits[i], y_train_splits[i], epochs=EPOCHS_WITHIN, batch_size=32, validation_split=0.1, verbose=VERBOSE)\n#         etime = time.time()\n#         fedTrainTime1 += etime - stime\n\n#         if VERBOSE: print(f\"Worker {i+1} trained in {etime - stime:.8f}s\")\n#         if VERBOSE > 2: print(f'{i}th model check: {check_quantization_type(models[i])}')\n#         if VERBOSE > 1: print(f'Precision of {i}th worker model: {models[i].get_weights()[0].dtype}')\n#         if VERBOSE > 3: print(f'Weights of {i}th worker model are: \\n {models[i].get_weights()}')\n\n#         worker_histories.append(history.history)\n#         worker_train_losses[i].append(history.history['loss'][0])\n#         worker_val_losses[i].append(history.history['val_loss'][0])\n#         worker_train_accuracies[i].append(history.history['accuracy'][0])\n#         worker_val_accuracies[i].append(history.history['val_accuracy'][0])\n\n#     # Collect and average the weights\n#     stime = time.time()\n#     new_weights = [model.get_weights() for model in models]\n#     avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n#     for model in models:\n#         model.set_weights(avg_weights)\n#     etime = time.time()\n\n#     fedTrainTime += (fedTrainTime1 / N_WORKERS) + etime - stime\n\n#     if VERBOSE > 1: print(f\"Worker weights updated in {etime - stime:.8f}s\")\n#     if VERBOSE > 2: print(f'Precision of avg model: {avg_weights[0].dtype}')\n#     if VERBOSE > 3: print(f'Weights of avg model are: \\n {avg_weights}')\n\n#     # Visualize weights after every VISUALIZE_WEIGHT_AFTER epochs\n#     if (epoch + 1) % VISUALIZE_WEIGHT_AFTER == 0:\n#         for i, model in enumerate(models):\n#             worker_weights[i].append(model.get_weights())\n\n#     # Print losses and accuracies for the epoch\n#     epoch_train_loss = np.mean([history['loss'][0] for history in worker_histories])\n#     epoch_val_loss = np.mean([history['val_loss'][0] for history in worker_histories])\n#     epoch_train_acc = np.mean([history['accuracy'][0] for history in worker_histories])\n#     epoch_val_acc = np.mean([history['val_accuracy'][0] for history in worker_histories])\n#     print(f'Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n#     print(f'Train Accuracy: {epoch_train_acc:.4f}, Val Accuracy: {epoch_val_acc:.4f}')\n\n# print(\"# 0.0 Training the models (fedML (none))\")\n# raw_fedML_model = global_model_and_test(models)  # Calculate the global model\n\n# print(f'0.1 Post-training pruning without fine-tuning')\n# post_pruned_models = [prune_model(model, ptype=\"ConstantSparsity\") for model in models]\n# postTrain_pruning_fedML_model = global_model_and_test(post_pruned_models)\n\n# EPOCHS_finetune = 1\n# fine_tune_callbacks = [\n#     tfmot.sparsity.keras.UpdatePruningStep(),\n#     tfmot.sparsity.keras.PruningSummaries(log_dir='./pruning_logs')\n# ]\n# fine_tuned_pruned_models = post_pruned_models\n\n# # Fine-tune the pruned raw models\n# fedTrainTime = 0\n# for epoch in range(EPOCHS_finetune):\n#     fedTrainTime1 = 0\n#     worker_histories = []\n#     print(f'Epoch {epoch+1}/{EPOCHS_finetune}')\n\n#     for i in range(N_WORKERS):\n#         stime = time.time()\n#         history = fine_tuned_pruned_models[i].fit(x_train_splits[i], y_train_splits[i], epochs=EPOCHS_WITHIN, batch_size=32, validation_split=0.1, verbose=VERBOSE, callbacks=fine_tune_callbacks)\n#         etime = time.time()\n#         fedTrainTime1 += etime - stime\n\n#         if VERBOSE: print(f\"Worker {i+1} trained in {etime - stime:.8f}s\")\n#         if VERBOSE > 2: print(f'{i}th model check: {check_quantization_type(fine_tuned_pruned_models[i])}')\n#         if VERBOSE > 1: print(f'Precision of {i}th worker model: {fine_tuned_pruned_models[i].get_weights()[0].dtype}')\n#         if VERBOSE > 3: print(f'Weights of {i}th worker model are: \\n {fine_tuned_pruned_models[i].get_weights()}')\n\n#         worker_histories.append(history.history)\n#         worker_train_losses[i].append(history.history['loss'][0])\n#         worker_val_losses[i].append(history.history['val_loss'][0])\n#         worker_train_accuracies[i].append(history.history['accuracy'][0])\n#         worker_val_accuracies[i].append(history.history['val_accuracy'][0])\n\n#     # Collect and average the weights\n#     stime = time.time()\n#     new_weights = [model.get_weights() for model in fine_tuned_pruned_models]\n#     avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n#     for model in fine_tuned_pruned_models:\n#         model.set_weights(avg_weights)\n#     etime = time.time()\n\n#     fedTrainTime += (fedTrainTime1 / N_WORKERS) + etime - stime\n\n#     if VERBOSE > 1: print(f\"Worker weights updated in {etime - stime:.8f}s\")\n#     if VERBOSE > 2: print(f'Precision of avg model: {avg_weights[0].dtype}')\n#     if VERBOSE > 3: print(f'Weights of avg model are: \\n {avg_weights}')\n\n#     # Visualize weights after every VISUALIZE_WEIGHT_AFTER epochs\n#     if (epoch + 1) % VISUALIZE_WEIGHT_AFTER == 0:\n#         for i, model in enumerate(fine_tuned_pruned_models):\n#             worker_weights[i].append(model.get_weights())\n\n#     # Print losses and accuracies for the epoch\n#     epoch_train_loss = np.mean([history['loss'][0] for history in worker_histories])\n#     epoch_val_loss = np.mean([history['val_loss'][0] for history in worker_histories])\n#     epoch_train_acc = np.mean([history['accuracy'][0] for history in worker_histories])\n#     epoch_val_acc = np.mean([history['val_accuracy'][0] for history in worker_histories])\n#     print(f'Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n#     print(f'Train Accuracy: {epoch_train_acc:.4f}, Val Accuracy: {epoch_val_acc:.4f}')\n\n# # Evaluate fine-tuned pruned models\n# print(\"# 0.2 Post-training pruning with fine-tuning\")\n# fineTuned_postTrain_pruning_fedML_model = global_model_and_test(post_pruned_models)\n\n# # Training the models with pruning-aware training\n# fedTrainTime = 0\n# for epoch in range(EPOCHS):\n#     fedTrainTime1 = 0\n#     worker_histories = []\n#     print(f'Epoch {epoch+1}/{EPOCHS}')\n\n#     for i in range(N_WORKERS):\n#         stime = time.time()\n#         history = pruned_models[i].fit(x_train_splits[i], y_train_splits[i], epochs=EPOCHS_WITHIN, batch_size=32, validation_split=0.1, verbose=VERBOSE, callbacks=[tfmot.sparsity.keras.UpdatePruningStep()])\n#         etime = time.time()\n#         fedTrainTime1 += etime - stime\n\n#         if VERBOSE: print(f\"Worker {i+1} trained in {etime - stime:.8f}s\")\n#         if VERBOSE > 2: print(f'{i}th model check: {check_quantization_type(pruned_models[i])}')\n#         if VERBOSE > 1: print(f'Precision of {i}th worker model: {pruned_models[i].get_weights()[0].dtype}')\n#         if VERBOSE > 3: print(f'Weights of {i}th worker model are: \\n {pruned_models[i].get_weights()}')\n\n#         worker_histories.append(history.history)\n#         worker_train_losses[i].append(history.history['loss'][0])\n#         worker_val_losses[i].append(history.history['val_loss'][0])\n#         worker_train_accuracies[i].append(history.history['accuracy'][0])\n#         worker_val_accuracies[i].append(history.history['val_accuracy'][0])\n\n#     # Collect and average the weights\n#     stime = time.time()\n#     new_weights = [model.get_weights() for model in pruned_models]\n#     avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n#     for model in pruned_models:\n#         model.set_weights(avg_weights)\n#     etime = time.time()\n\n#     fedTrainTime += (fedTrainTime1 / N_WORKERS) + etime - stime\n\n#     if VERBOSE > 1: print(f\"Worker weights updated in {etime - stime:.8f}s\")\n#     if VERBOSE > 2: print(f'Precision of avg model: {avg_weights[0].dtype}')\n#     if VERBOSE > 3: print(f'Weights of avg model are: \\n {avg_weights}')\n\n#     # Visualize weights after every VISUALIZE_WEIGHT_AFTER epochs\n#     if (epoch + 1) % VISUALIZE_WEIGHT_AFTER == 0:\n#         for i, model in enumerate(pruned_models):\n#             worker_weights[i].append(model.get_weights())\n\n#     # Print losses and accuracies for the epoch\n#     epoch_train_loss = np.mean([history['loss'][0] for history in worker_histories])\n#     epoch_val_loss = np.mean([history['val_loss'][0] for history in worker_histories])\n#     epoch_train_acc = np.mean([history['accuracy'][0] for history in worker_histories])\n#     epoch_val_acc = np.mean([history['val_accuracy'][0] for history in worker_histories])\n#     print(f'Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n#     print(f'Train Accuracy: {epoch_train_acc:.4f}, Val Accuracy: {epoch_val_acc:.4f}')\n\n# # Calculate the global pruneTraining_fedML_model\n# print(\"# 1.0 Training the models with pruning aware training\")\n# pruneTraining_fedML_model = global_model_and_test(pruned_models)\n\n# pruned_fine_tune_callbacks = [\n#     tfmot.sparsity.keras.UpdatePruningStep(),\n#     tfmot.sparsity.keras.PruningSummaries(log_dir='./pruning_logs')\n# ]\n# fine_tuned_prune_aware_models = pruned_models\n\n# # Fine-tune the pruned models\n# fedTrainTime = 0\n# for epoch in range(EPOCHS_finetune):\n#     fedTrainTime1 = 0\n#     worker_histories = []\n#     print(f'Epoch {epoch+1}/{EPOCHS_finetune}')\n\n#     for i in range(N_WORKERS):\n#         stime = time.time()\n#         history = fine_tuned_prune_aware_models[i].fit(x_train_splits[i], y_train_splits[i], epochs=EPOCHS_WITHIN, batch_size=32, validation_split=0.1, verbose=VERBOSE, callbacks=pruned_fine_tune_callbacks)\n#         etime = time.time()\n#         fedTrainTime1 += etime - stime\n\n#         if VERBOSE: print(f\"Worker {i+1} trained in {etime - stime:.8f}s\")\n#         if VERBOSE > 2: print(f'{i}th model check: {check_quantization_type(fine_tuned_prune_aware_models[i])}')\n#         if VERBOSE > 1: print(f'Precision of {i}th worker model: {fine_tuned_prune_aware_models[i].get_weights()[0].dtype}')\n#         if VERBOSE > 3: print(f'Weights of {i}th worker model are: \\n {fine_tuned_prune_aware_models[i].get_weights()}')\n\n#         worker_histories.append(history.history)\n#         worker_train_losses[i].append(history.history['loss'][0])\n#         worker_val_losses[i].append(history.history['val_loss'][0])\n#         worker_train_accuracies[i].append(history.history['accuracy'][0])\n#         worker_val_accuracies[i].append(history.history['val_accuracy'][0])\n\n#     # Collect and average the weights\n#     stime = time.time()\n#     new_weights = [model.get_weights() for model in fine_tuned_prune_aware_models]\n#     avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n#     for model in fine_tuned_prune_aware_models:\n#         model.set_weights(avg_weights)\n#     etime = time.time()\n\n#     fedTrainTime += (fedTrainTime1 / N_WORKERS) + etime - stime\n\n#     if VERBOSE > 1: print(f\"Worker weights updated in {etime - stime:.8f}s\")\n#     if VERBOSE > 2: print(f'Precision of avg model: {avg_weights[0].dtype}')\n#     if VERBOSE > 3: print(f'Weights of avg model are: \\n {avg_weights}')\n\n#     # Visualize weights after every VISUALIZE_WEIGHT_AFTER epochs\n#     if (epoch + 1) % VISUALIZE_WEIGHT_AFTER == 0:\n#         for i, model in enumerate(fine_tuned_prune_aware_models):\n#             worker_weights[i].append(model.get_weights())\n\n#     # Print losses and accuracies for the epoch\n#     epoch_train_loss = np.mean([history['loss'][0] for history in worker_histories])\n#     epoch_val_loss = np.mean([history['val_loss'][0] for history in worker_histories])\n#     epoch_train_acc = np.mean([history['accuracy'][0] for history in worker_histories])\n#     epoch_val_acc = np.mean([history['val_accuracy'][0] for history in worker_histories])\n#     print(f'Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n#     print(f'Train Accuracy: {epoch_train_acc:.4f}, Val Accuracy: {epoch_val_acc:.4f}')\n\n# # Evaluate fine-tuned pruned models\n# print(\"# 1.2 Training the models with pruning aware training with finetuning\")\n# fineTuned_postTrain_pruning_fedML_model = global_model_and_test(fine_tuned_prune_aware_models)\n\n# # Restore the original policy\n# tf.keras.mixed_precision.set_global_policy(None)\n","metadata":{"id":"0bqWgDXzMFqc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### gg","metadata":{"id":"7xm0AtHvpx1X"}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport time\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow_model_optimization as tfmot\n\n# Enable mixed precision policy if needed\nenable_mixed_precision_policy = True\nif enable_mixed_precision_policy:\n    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n    tf.keras.mixed_precision.set_global_policy(policy)\n\n\ndef compile_model(model):\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\ndef create_model(precision: str = 'float32'):\n    if precision == 'float32':\n        precision = tf.float32\n        model = keras.Sequential([\n            keras.layers.InputLayer(input_shape=(28, 28, 1)),\n            keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n            keras.layers.MaxPooling2D(pool_size=(2, 2)),\n            keras.layers.Flatten(),\n            keras.layers.Dense(64, activation='relu'),\n            keras.layers.Dense(10, activation='softmax')\n        ])\n    elif precision == 'float16':\n        precision = tf.float16\n        model = models.Sequential([\n            layers.InputLayer(input_shape=(28, 28)),\n            layers.Reshape(target_shape=(28, 28, 1)),\n            layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu', dtype=precision),\n            layers.MaxPooling2D(pool_size=(2, 2)),\n            layers.Flatten(),\n            layers.Dense(64, dtype=precision),\n            layers.Dense(10, dtype=precision)\n        ])\n    else:\n        pass\n\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\ndef prune_model(model, ptype:str = \"PolynomialDecay\",\n                initial_sparsity = 0.0, final_sparsity = 0.5,\n                begin_step = 0, end_step = -1):\n    if ptype == \"PolynomialDecay\":\n        # Define a pruning schedule using PolynomialDecay\n        pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n            initial_sparsity=0.0,  # initial_sparsity: float, the initial level of sparsity (0.0 means no pruning at the start).\n            final_sparsity=0.5,    # final_sparsity: float, the target level of sparsity (0.5 means 50% of weights will be pruned).\n            begin_step=0,          # begin_step: int, the step at which pruning begins (0 means pruning starts at the beginning).\n            end_step=np.ceil(x_train.shape[0] / 64).astype(np.int32) * EPOCHS  # end_step: int, the step at which pruning ends, calculated based on total training steps.\n            # Step at which to end pruning. -1 by default. -1 implies continuing to prune till the end of training.\n        )\n\n        # Apply pruning to the model using the defined pruning schedule\n        model = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule=pruning_schedule)\n\n    elif ptype == \"ConstantSparsity\":\n        # Define a pruning schedule using ConstantSparsity\n        pruning_params = {\n        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(\n            target_sparsity=0.5,    # target_sparsity: float, the desired level of sparsity in the model's weights.\n                                    # 0.5 means that 50% of the weights will be pruned (set to zero).\n                                    # For example, if set to 0.8, 80% of the weights will be pruned.\n\n            begin_step=0,           # begin_step: int, the step at which pruning begins.\n                                    # 0 means pruning starts from the very beginning of training.\n                                    # For example, if set to 1000, pruning will start after 1000 training steps.\n\n            frequency=1             # frequency: int, the frequency (in number of steps) with which pruning is applied.\n                                    # 100 means the pruning function will be applied every 100 steps during training.\n                                    # This allows for gradual pruning, helping the model adapt to the reduced weights.\n        )\n        }\n        model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n\n    else:\n        pass\n\n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\ndef global_model_and_test(models):\n    new_weights = [model.get_weights() for model in models]\n    avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n    # for model in models:\n    #     model.set_weights(avg_weights)\n\n    model = models[0]\n    model.compile(optimizer='adam',\n                        loss='sparse_categorical_crossentropy',\n                        metrics=['accuracy'])\n    model.set_weights(avg_weights)\n\n    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n    print(f'Test accuracy: {test_acc}')\n\n    return model\n\n\n# # 0.0 Training then pruning    (Post - Train Pruning)\n# # 0.1 without fine-tuning     :: post-training with pruning without fine-tuning\n# # 0.2 with fine-tuning        :: post-training with pruning with fine-tuning\n\n# # 1. Pruning aware training  (Pruning aware Training)\n# # 1.0 without fine-tuning     :: pre-training with pruning without fine-tuning\n### 1.2 with fine-tuning        :: pre-training with pruning with    fine-tuning\n\n\n# Initialize models for each worker\nmodels = [create_model() for _ in range(N_WORKERS)]\npruned_models = [prune_model(model) for model in models]\n\n# 0.0 Training the models (fedML (none))\nfedTrainTime = 0\nfor epoch in range(EPOCHS):\n    fedTrainTime1 = 0\n    worker_histories = []\n    print(f'Epoch {epoch+1}/{EPOCHS}')\n\n    for i in range(N_WORKERS):\n        stime = time.time()\n        history = models[i].fit(x_train_splits[i], y_train_splits[i], epochs=EPOCHS_WITHIN, batch_size=32, validation_split=0.1, verbose=VERBOSE)\n        etime = time.time()\n        fedTrainTime1 += etime - stime\n\n        if VERBOSE: print(f\"Worker {i+1} trained in {fedTrainTime1:.8f}s\")\n        worker_histories.append(history.history)\n\n    # Collect and average the weights\n    stime = time.time()\n    new_weights = [model.get_weights() for model in models]\n    avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n    for model in models:\n        model.set_weights(avg_weights)\n    etime = time.time()\n\n    fedTrainTime += (fedTrainTime1 / N_WORKERS) + etime - stime\n\n    if VERBOSE: print(f\"Worker weights updated in {fedTrainTime:.8f}s\")\n\nprint(\"# 0.0 Training the models (fedML (none))\")\nraw_fedML_model = global_model_and_test(models)        # :: Calculate the global model\nhistory = models[i].fit(x_train_splits[i][:8], y_train_splits[i][:8], epochs=EPOCHS_WITHIN, batch_size=8, validation_split=0.0, verbose=VERBOSE)\n# print(f\"For training model with {N_WORKERS} workers for {EPOCHS} epochs, time taken is {etime-stime:.4f}s\")\n\n\nprint(f'0.1 Post-training pruning without fine-tuning')\npost_pruned_models = [prune_model(model,ptype= \"ConstantSparsity\") for model in models]\npostTrain_pruning_fedML_model = global_model_and_test(post_pruned_models)\n\n\nEPOCHS_finetune = 1\nfine_tune_callbacks = [\n    tfmot.sparsity.keras.UpdatePruningStep(),\n    tfmot.sparsity.keras.PruningSummaries(log_dir='./pruning_logs')\n    ]\nfine_tuned_pruned_models = post_pruned_models # [prune_model(model, ptype = \"ConstantSparsity\") for model in models]\n\n# Fine-tune the pruned raw-models\nfedTrainTime = 0\nfor epoch in range(EPOCHS_finetune):\n    fedTrainTime1 = 0\n    worker_histories = []\n    print(f'Epoch {epoch+1}/{EPOCHS}')\n\n    for i in range(N_WORKERS):\n        stime = time.time()\n        history = fine_tuned_pruned_models[i].fit(x_train_splits[i], y_train_splits[i], epochs=EPOCHS_WITHIN, batch_size=32, validation_split=0.1, verbose=VERBOSE, callbacks=fine_tune_callbacks)\n        etime = time.time()\n        fedTrainTime1 += etime - stime\n\n        if VERBOSE: print(f\"Worker {i+1} trained in {fedTrainTime1:.8f}s\")\n        worker_histories.append(history.history)\n\n    # Collect and average the weights\n    stime = time.time()\n    new_weights = [model.get_weights() for model in fine_tuned_pruned_models]\n    avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n    for model in fine_tuned_pruned_models:\n        model.set_weights(avg_weights)\n    etime = time.time()\n\n    fedTrainTime += (fedTrainTime1 / N_WORKERS) + etime - stime\n\n    if VERBOSE: print(f\"Worker weights updated in {fedTrainTime:.8f}s\")\n\n# Evaluate fine-tuned pruned models\nprint(\"# 0.2 Post-training pruning with fine-tuning\")\nfineTuned_postTrain_pruning_fedML_model = global_model_and_test(post_pruned_models)\n\n\n\n\n\n# Training the models with pruning aware training\nfedTrainTime = 0\nfor epoch in range(EPOCHS):\n    fedTrainTime1 = 0\n    worker_histories = []\n    print(f'Epoch {epoch+1}/{EPOCHS}')\n\n    for i in range(N_WORKERS):\n        stime = time.time()\n        history = pruned_models[i].fit(x_train_splits[i], y_train_splits[i], epochs=EPOCHS_WITHIN, batch_size=32, validation_split=0.1, verbose=VERBOSE,  callbacks=[tfmot.sparsity.keras.UpdatePruningStep()])\n        etime = time.time()\n        fedTrainTime1 += etime - stime\n\n        if VERBOSE: print(f\"Worker {i+1} trained in {fedTrainTime1:.8f}s\")\n        worker_histories.append(history.history)\n\n    # Collect and average the weights\n    stime = time.time()\n    new_weights = [model.get_weights() for model in pruned_models]\n    avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n    for model in pruned_models:\n        model.set_weights(avg_weights)\n    etime = time.time()\n\n    fedTrainTime += (fedTrainTime1 / N_WORKERS) + etime - stime\n\n    if VERBOSE: print(f\"Worker weights updated in {fedTrainTime:.8f}s\")\n\n# Calculate the global pruneTraining_fedML_model\nprint(\"# 1.0 Training the models with pruning aware training\")\npruneTraining_fedML_model = global_model_and_test(pruned_models)\n# print(f\"For training model with {N_WORKERS} workers for {EPOCHS} epochs, time taken is {etime-stime:.4f}s\")\n\n\npruned_fine_tune_callbacks = [\n    tfmot.sparsity.keras.UpdatePruningStep(),\n    tfmot.sparsity.keras.PruningSummaries(log_dir='./pruning_logs')\n    ]\nfine_tuned_prune_aware_models = pruned_models # [prune_model(model, ptype = \"ConstantSparsity\") for model in models]\n\n# Fine-tune the pruned raw-models\nfedTrainTime = 0\nfor epoch in range(EPOCHS_finetune):\n    fedTrainTime1 = 0\n    worker_histories = []\n    print(f'Epoch {epoch+1}/{EPOCHS}')\n\n    for i in range(N_WORKERS):\n        stime = time.time()\n        history = fine_tuned_prune_aware_models[i].fit(x_train_splits[i], y_train_splits[i], epochs=EPOCHS_WITHIN, batch_size=32, validation_split=0.1, verbose=VERBOSE, callbacks=pruned_fine_tune_callbacks)\n        etime = time.time()\n        fedTrainTime1 += etime - stime\n\n        if VERBOSE: print(f\"Worker {i+1} trained in {fedTrainTime1:.8f}s\")\n        worker_histories.append(history.history)\n\n    # Collect and average the weights\n    stime = time.time()\n    new_weights = [model.get_weights() for model in fine_tuned_prune_aware_models]\n    avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n    for model in fine_tuned_prune_aware_models:\n        model.set_weights(avg_weights)\n    etime = time.time()\n\n    fedTrainTime += (fedTrainTime1 / N_WORKERS) + etime - stime\n\n    if VERBOSE: print(f\"Worker weights updated in {fedTrainTime:.8f}s\")\n\n# Evaluate fine-tuned pruned models\nprint(\"# 1.2 Training the models with pruning aware training with finetuning\")\nfineTuned_postTrain_pruning_fedML_model = global_model_and_test(fine_tuned_prune_aware_models)\n\n\n\n\n\n\n# Restore the original policy\ntf.keras.mixed_precision.set_global_policy(None)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UId2myQf4u5M","executionInfo":{"status":"ok","timestamp":1719571802028,"user_tz":-330,"elapsed":111932,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"outputId":"021f423a-ca93-4a37-a3df-ad93df8a8383"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compare_model_weights(model1, model2):\n    layers1 = model1.layers\n    layers2 = model2.layers\n\n    for layer1, layer2 in zip(layers1, layers2):\n        weights1 = layer1.get_weights()\n        weights2 = layer2.get_weights()\n        print(f\"Layer {layer1.name} / {layer2.name}\")\n        for i, (w1, w2) in enumerate(zip(weights1, weights2)):\n            are_weights_equal = np.array_equal(w1, w2)\n            print(f\"  Weight {i + 1}:\")\n            print(f\"    Are weights equal? {are_weights_equal}\")\n\n# Compare weights of the two models\ncompare_model_weights(models[-1], pruned_models[-1])\n\n# [ 0.          0.          0.         -0.30790305  0.19578068\n#      0.23647237  0.19294487  0.          0.14917755  0.\n#      0.         -0.48902744  0.1838266  -0.46426666  0.\n#      0.          0.1348818   0.01700406  0.         -0.19746181\n#      0.          0.23833129  0.1361009  -0.18042842  0.2017729\n#      0.          0.         -0.42712042  0.3622789   0.\n#     -0.23073876  0.        ]\n\n# [ 0.          0.          0.         -0.30790305  0.19578068\n#      0.23647237  0.19294487  0.          0.14917755  0.\n#      0.         -0.48902744  0.1838266  -0.46426666  0.\n#      0.          0.1348818   0.01700406  0.         -0.19746181\n#      0.          0.23833129  0.1361009  -0.18042842  0.2017729\n#      0.          0.         -0.42712042  0.3622789   0.\n#     -0.23073876  0.        ]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pog7TBVRmGi","executionInfo":{"status":"ok","timestamp":1719572081299,"user_tz":-330,"elapsed":668,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"}},"outputId":"a11a97d9-16fc-46b8-ed85-44ca953225ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport time\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow_model_optimization.python.core.keras.compat import keras\n\nenable_mixed_precision_policy = False\nif enable_mixed_precision_policy:\n    policy = tf.keras.mixed_precision.Policy('mixed_float16')\n    tf.keras.mixed_precision.set_global_policy(policy)\n\ndef create_model(precision:str = 'float32'):\n    if precision == 'float16':\n        model = models.Sequential([\n            layers.InputLayer(input_shape=(28, 28)),\n            layers.Reshape(target_shape=(28, 28, 1)),\n            layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu', dtype = 'float16'),\n            layers.MaxPooling2D(pool_size=(2, 2)),\n            layers.Flatten(),\n            layers.Dense(64, dtype='float16'),  # Ensure Dense layer uses float32 for variables\n            layers.Dense(10, dtype='float16')   # Ensure Dense layer uses float32 for variables\n        ])\n\n    else:\n        model = models.Sequential([\n            layers.InputLayer(input_shape=(28, 28)),\n            layers.Reshape(target_shape=(28, 28, 1)),\n            layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n            layers.MaxPooling2D(pool_size=(2, 2)),\n            layers.Flatten(),\n            layers.Dense(64),  # Ensure Dense layer uses float32 for variables\n            layers.Dense(10)   # Ensure Dense layer uses float32 for variables\n        ])\n\n    model.compile(optimizer=Adam(),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    return model\n\n# Initialize lists to store weights, training and validation losses and accuracies for each worker\nworker_weights, worker_train_losses, worker_val_losses, worker_train_accuracies, worker_val_accuracies = ([[] for _ in range(N_WORKERS)] for _ in range(5))\n\n\n# Initialize and quantize models for each worker\nmodels = [create_model() for _ in range(N_WORKERS)]\nprint(models[0].summary())\n\nfedTrainTime = 0\nfor epoch in range(EPOCHS):\n    fedTrainTime1 = 0\n    worker_histories = []\n    print(f'Epoch {epoch+1}/{EPOCHS}')\n\n    # Train each worker's model for {EPOCHS_WITHIN} epoch\n    for i in range(N_WORKERS):\n        stime = time.time()\n        history = models[i].fit(x_train_splits[i], y_train_splits[i], epochs=EPOCHS_WITHIN, batch_size=32, validation_split=0.1, verbose=VERBOSE)\n        etime = time.time()\n        fedTrainTime1 += etime - stime\n\n        if (VERBOSE) : print(f\"Worker {i+1} trained in {fedTrainTime1:.8f}s\")\n        if (VERBOSE > 2) : print(f'{i}th model check : {check_quantization_type(models[i])}')\n        if (VERBOSE > 1) : print(f'Presicion of {i} th worker model {models[i].get_weights()[0].dtype}')\n        if (VERBOSE > 3) : print(f'Weights of {i} th worker model are :: \\n {models[i].get_weights()}')\n\n        worker_histories.append(history.history)\n        worker_train_losses[i].append(history.history['loss'][0])\n        worker_val_losses[i].append(history.history['val_loss'][0])\n        worker_train_accuracies[i].append(history.history['accuracy'][0])\n        worker_val_accuracies[i].append(history.history['val_accuracy'][0])\n\n    # Collect and average the weights\n    stime = time.time()\n    new_weights = [model.get_weights() for model in models]\n    avg_weights = [np.mean([new_weights[j][k] for j in range(N_WORKERS)], axis=0) for k in range(len(new_weights[0]))]\n    for model in models:\n        model.set_weights(avg_weights)\n    etime = time.time()\n\n    fedTrainTime += (fedTrainTime1 / N_WORKERS) + etime - stime\n\n    if VERBOSE > 1 : print(f\"Worker weights updated in {fedTrainTime:.8f}s\")\n    if VERBOSE > 2 : print(f'Presicion of avg model {avg_weights[0].dtype}')\n    if VERBOSE > 3 : print(f'Weights of avg model are :: \\n {avg_weights}')\n\n    # Visualize weights after every VISUALIZE_WEIGHT_AFTER epochs\n    if (epoch + 1) % VISUALIZE_WEIGHT_AFTER == 0:\n        for i, model in enumerate(models):\n            worker_weights[i].append(model.get_weights())\n\n    # Print losses and accuracies for the epoch\n    epoch_train_loss = np.mean([history['loss'][0] for history in worker_histories])\n    epoch_val_loss = np.mean([history['val_loss'][0] for history in worker_histories])\n    epoch_train_acc = np.mean([history['accuracy'][0] for history in worker_histories])\n    epoch_val_acc = np.mean([history['val_accuracy'][0] for history in worker_histories])\n    print(f'Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}')\n    print(f'Train Accuracy: {epoch_train_acc:.4f}, Val Accuracy: {epoch_val_acc:.4f}')\n\n# # Restore the original policy\ntf.keras.mixed_precision.set_global_policy(None)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"TCxJd8lE0evw","outputId":"71b345e9-7040-4e62-a243-173dadbf074c","executionInfo":{"status":"error","timestamp":1719812665091,"user_tz":-330,"elapsed":10574,"user":{"displayName":"Vickey Kumar","userId":"02587512178673317676"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Calculate the global model\nfinal_model = create_model()\nfinal_model.compile(optimizer=Adam(),\n                    loss='sparse_categorical_crossentropy',\n                    metrics=['accuracy'])\nfinal_model.set_weights(avg_weights)\n\ntest_loss, test_acc = final_model.evaluate(x_test, y_test, verbose=0)\nprint(f'Test accuracy: {test_acc}')\n\nprint(f\"For training model with {N_WORKERS} workers for {EPOCHS} epochs, time taken is {etime-stime:.4f}s\")\n\n\npolicy = tf.keras.mixed_precision.Policy('mixed_float16')\ntf.keras.mixed_precision.set_global_policy(policy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22047,"status":"ok","timestamp":1718964158442,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"},"user_tz":-330},"id":"dbWqHrZuPp_Z","outputId":"ea32e3a3-2f83-4538-e6be-4a9bf742901b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_quantization_type(final_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":574,"status":"ok","timestamp":1718964166925,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"},"user_tz":-330},"id":"xtyRs5G5I5A0","outputId":"79de8918-0837-42a0-e752-0ac5adeb0ab4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  Calculate the global model\nfinal_model = create_model()\nfinal_model.compile(optimizer=Adam(),\n                    loss='sparse_categorical_crossentropy',\n                    metrics=['accuracy'])\nfinal_model.set_weights(avg_weights)\ncheck_quantization_type(final_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":672,"status":"ok","timestamp":1718964188010,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"},"user_tz":-330},"id":"loFOjEaf0evw","outputId":"1e0e4c0d-e326-4ec1-925a-70ad15f67442"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Function to prepare data for plotting\ndef prepare_data_for_plotting(worker_metrics, metric_name, ttype=\"Training\"):\n    data = []\n    for i in range(N_WORKERS):\n        for epoch in range(EPOCHS):\n            data.append([epoch + 1, worker_metrics[i][epoch], f'Worker {i+1}', f'{ttype} {metric_name}'])\n    return pd.DataFrame(data, columns=['Epoch', metric_name, 'Worker', 'Type'])\n\n# Prepare data for plotting\ntrn_loss_df = prepare_data_for_plotting(worker_train_losses, 'Loss')\nval_loss_df = prepare_data_for_plotting(worker_val_losses, 'Loss', ttype=\"Validation\")\n\ntrn_accuracy_df = prepare_data_for_plotting(worker_train_accuracies, 'Accuracy')\nval_accuracy_df = prepare_data_for_plotting(worker_val_accuracies, 'Accuracy', ttype=\"Validation\")\n\n# Combine the data for losses and accuracies\nloss_df = pd.concat([trn_loss_df, val_loss_df])\naccuracy_df = pd.concat([trn_accuracy_df, val_accuracy_df])\n\n# Plot losses\nplt.figure(figsize=(14, 8))\nsns.lineplot(data=loss_df, x='Epoch', y='Loss', hue='Worker', style='Type', markers=True, dashes=False)\nplt.title('Training and Validation Losses for Each Worker')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='upper right')\nplt.show()\n\n# Plot accuracies\nplt.figure(figsize=(14, 8))\nsns.lineplot(data=accuracy_df, x='Epoch', y='Accuracy', hue='Worker', style='Type', markers=True, dashes=False)\nplt.title('Training and Validation Accuracies for Each Worker')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='lower right')\nplt.show()\n\n# Print metrics\nprint(f'Test accuracy: {test_acc}')\nprint('Confusion Matrix:')\nprint(confusion_matrix(y_test, y_pred_classes))\nprint('Classification Report:')\nprint(classification_report(y_test, y_pred_classes))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":620,"status":"error","timestamp":1718964269421,"user":{"displayName":"Lakshay Kumar","userId":"06114832598799728836"},"user_tz":-330},"id":"jo0sxiVA0evw","outputId":"5412259b-a1e2-4fee-a03b-62ab05ec9f9a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mean_axis_0(lst):\n    num_rows = len(lst)\n    num_cols = len(lst[0]) if lst else 0\n    if num_cols == 0:\n        return []\n    min_len = min(len(row) for row in lst)\n    col_means = []\n    for j in range(min_len):\n        col_sum = sum(lst[i][j] for i in range(num_rows))\n        col_mean = col_sum / num_rows\n        col_means.append(col_mean)\n    return col_means , min_len\n\n\ndef plot_weight_distributions_across_epochs(worker_weights, epochs, n_sigma_away=1, bucket_size=0.001):\n    num_workers = len(worker_weights)\n    cols = (num_workers)+1  # Number of columns for subplots\n\n    for epoch in range(epochs):\n        fig, axes = plt.subplots(1, cols, figsize=(cols * 5, 5))  # Adjust figsize for wider graphs\n        fig.suptitle(f\"PDF Distribution of Weights - Epoch {epoch + 1}\", fontsize=32)\n\n        store_hist = []\n        for worker_id, weights_history in enumerate(worker_weights):\n            # Check if there are any epochs to plot\n            if epoch >= len(weights_history):\n                print(f\"No epochs to plot for Worker {worker_id + 1}\")\n                continue\n\n            flattened_weights = np.concatenate([w.flatten() for w in weights_history[epoch]])\n\n            # Remove weights that are n_sigma_away from the mean\n            mean_weight = np.mean(flattened_weights)\n            std_weight = np.std(flattened_weights)\n            filtered_weights = flattened_weights[np.abs(flattened_weights - mean_weight) <= n_sigma_away * std_weight]\n\n            min_weight = min(filtered_weights)\n            max_weight = max(filtered_weights)\n\n            bins = np.arange(min_weight, max_weight, bucket_size)\n            hist, _ = np.histogram(filtered_weights, bins=bins, density=True)\n\n            store_hist.append(np.array(hist))\n\n            ax = axes[worker_id]\n            sns.histplot(filtered_weights, bins=bins, kde=True, ax=ax)\n            ax.set_title(f\"Worker {worker_id + 1}\")\n            ax.set_xlabel(\"Weight Value (ignore values)\")\n            ax.set_ylabel(\"Density\")\n\n        avg_hist, min_len = mean_axis_0(store_hist)\n        diff_hist = [hist[:min_len] - avg_hist for hist in store_hist]\n#         diff_hist = [hist[:min_len] - store_hist[-1][:min_len] for hist in store_hist]\n\n\n        plt.plot(avg_hist)\n        plt.title(f\"Avg Worker\")\n        plt.xlabel(\"Weight Value\")\n        plt.ylabel(\"Density\")\n        plt.show()\n\n        for i in range(len(diff_hist)):\n            diff_hist[i] = [2000*j for j in diff_hist[i]]\n\n        plt.figure(figsize=(20, 10))  # Adjust the figure size as needed\n        for i, sublist in enumerate(diff_hist):\n            x = np.arange(len(sublist))\n            y = sublist\n            plt.scatter(x, y, label=f'Worker {i+1}')\n            plt.title(f\"Dot plot of Difference of Worker{i}\")\n            plt.xlabel(\"Weight Value (ignore values)\")\n            plt.ylabel(\"Density\")\n            plt.legend()\n\n\n        for i in range(len(diff_hist)):\n            plt.plot(diff_hist[i])\n            plt.title(f\"Difference of Worker to the average\")\n            plt.xlabel(\"Weight Value (ignore values)\")\n            plt.ylabel(\"Density\")\n            plt.legend()\n\n        plt.tight_layout(rect=[0, 0, 1, 0.95])\n        plt.show()\n\n#         break\n#         return avg_hist, store_hist\n\n# Call the function to plot weight distributions across epochs\nplot_weight_distributions_across_epochs(worker_weights, EPOCHS)\n","metadata":{"id":"wTFN5VzN0evz","outputId":"5cc16f4a-dc83-4375-c4dc-ddcac69d1f01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(models[0].summary())\n\n# Iterate over each epoch\nfor epoch in range(len(worker_weights[0])):\n    # Iterate over each layer\n    for layer_id in range(len(worker_weights[0][0])):\n        # Initialize an empty list to store flattened weights of the current layer for all workers\n        layer_weights_all_workers = []\n\n        # Collect weights of the current layer for all workers at the current epoch\n        for worker_id, weights_history in enumerate(worker_weights):\n            # Append the flattened weights of the current layer for the current worker and epoch\n            layer_weights_all_workers.append(weights_history[epoch][layer_id].flatten())\n\n        # Plot the histograms of weights of the current layer for all workers in one figure\n        plt.figure(figsize=(10, 5))\n        plt.hist(layer_weights_all_workers, bins=50, label=[f'Worker {i+1}' for i in range(N_WORKERS)], alpha=0.7)\n        plt.title(f'Epoch {epoch + 1}, Layer {layer_id + 1} - Distribution of Weights')\n        plt.xlabel('Weight Value')\n        plt.ylabel('Frequency')\n        plt.legend()\n        plt.show()","metadata":{"id":"ET1Uv7Oj0evz","outputId":"029082c7-6536-47b7-c7cb-8d8fd2ed7d5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_weight_distribution(weights_history, worker_id, n_sigma_away=1, bucket_size=0.001):\n    num_epochs = len(weights_history)\n\n    # Check if there are any epochs to plot\n    if num_epochs == 0:\n        print(f\"No epochs to plot for Worker {worker_id + 1}\")\n        return\n\n    cols = N_WORKERS  # Number of columns for subplots\n    rows = num_epochs  # Calculate the number of rows needed\n\n    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))  # Adjust figsize for wider graphs\n    fig.suptitle(f\"PDF Distribution of Weights for Worker {worker_id + 1}\", fontsize=32)\n\n    bin_values = []\n\n    for epoch, weights in enumerate(weights_history):\n        flattened_weights = np.concatenate([w.flatten() for w in weights])\n\n        # Remove weights that are 3 sigma away from the mean\n        mean_weight = np.mean(flattened_weights)\n        std_weight = np.std(flattened_weights)\n        filtered_weights = flattened_weights[np.abs(flattened_weights - mean_weight) <= n_sigma_away * std_weight]\n\n        min_weight = min(filtered_weights)\n        max_weight = max(filtered_weights)\n\n        bins = np.arange(min_weight, max_weight, bucket_size)\n        hist, _ = np.histogram(filtered_weights, bins=bins, density=True)\n\n        bin_values.append(hist)\n\n        ax = axes[epoch // cols, epoch % cols]\n        sns.histplot(filtered_weights, bins=bins, kde=True, ax=ax)\n        ax.set_title(f\"Epoch {epoch + 1}\")\n        ax.set_xlabel(\"Weight Value\")\n        ax.set_ylabel(\"Density\")\n\n    # Remove any empty subplots\n    for i in range(num_epochs, rows * cols):\n        fig.delaxes(axes.flatten()[i])\n\n    plt.tight_layout(rect=[0, 0, 1, 1])\n    plt.show()\n\n    return bin_values\n\nhistograms_array = [[] for i in range(EPOCHS)]\n# Visualize weights for each worker\nfor worker_id, weights_history in enumerate(worker_weights):\n    tmp2 = [i for i in plot_weight_distribution(weights_history, worker_id)]\n    for i in range(EPOCHS):\n        histograms_array[i].append((tmp2[i]))","metadata":{"id":"XfHStdxy0evz","outputId":"debe34b1-da44-42c6-9394-64079e01e154"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Full plot with sigma away ; Low visuality\n\n# Define function to remove outliers and plot PDF distribution of weights\ndef plot_weight_distribution(weights_history, worker_id, bucket_size=0.001):\n    num_epochs = len(weights_history)\n    cols = N_WORKERS  # Number of columns for subplots\n    rows = num_epochs  # Calculate the number of rows needed\n\n    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))  # Adjust figsize for wider graphs\n    fig.suptitle(f\"PDF Distribution of Weights for Worker {worker_id + 1}\", fontsize=16)\n\n    for epoch, weights in enumerate(weights_history):\n        flattened_weights = np.concatenate([w.flatten() for w in weights])\n\n        # Remove weights that are 3 sigma away from the mean\n        mean_weight = np.mean(flattened_weights)\n        std_weight = np.std(flattened_weights)\n        filtered_weights = flattened_weights[np.abs(flattened_weights - mean_weight) <= 3 * std_weight]\n\n        min_weight = min(filtered_weights)\n        max_weight = max(filtered_weights)\n\n        bins = np.arange(min_weight, max_weight, bucket_size)\n\n        ax = axes[epoch // cols, epoch % cols]\n        sns.histplot(filtered_weights, bins=bins, kde=True, ax=ax)\n        ax.set_title(f\"Epoch {epoch + 1}\")\n        ax.set_xlabel(\"Weight Value\")\n        ax.set_ylabel(\"Density\")\n\n    # Remove any empty subplots\n    for i in range(num_epochs, rows * cols):\n        fig.delaxes(axes.flatten()[i])\n\n    plt.tight_layout(rect=[0, 0, 1, 1])\n    plt.show()\n\n# Visualize weights for each worker\nfor worker_id, weights_history in enumerate(worker_weights):\n    plot_weight_distribution(weights_history, worker_id)\n#     break  # Remove this line if you want to visualize for all workers\n","metadata":{"id":"oTQQj9ti0ev0","outputId":"5418ea85-6715-46fc-9ff6-1064726c2cc6"},"execution_count":null,"outputs":[]}]}